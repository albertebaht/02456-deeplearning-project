{"text": "Errors-in-variables Modeling of Personalized\nTreatment-Response Trajectories\nGuangyi Zhang1, Reza Ashra\ufb011, Anne Juuti2, Kirsi Pietil\u00a8ainen2, and Pekka Marttinen1\n1 Aalto University, Finland\n{guangyi.zhang,reza.ashrafi,pekka.marttinen}@aalto.fi\n2 University of Helsinki, Finland\nanne.juuti@hus.fi,kirsi.pietilainen@helsinki.fi\nAbstract. Estimating the e\ufb00ect of a treatment on a given outcome, conditioned\non a vector of covariates, is central in many applications. However, learning the\nimpact of a treatment on a continuous temporal response, when the covariates\nsu\ufb00er extensively from measurement error and even the timing of the treatments\nis uncertain, has not been addressed. We introduce a novel data-driven method\nthat can estimate treatment-response trajectories in this challenging scenario. We\nmodel personalized treatment-response curves as a combination of parametric\nresponse functions, hierarchically sharing information across individuals, and a\nsparse Gaussian process for the baseline trend. Importantly, our model considers\nmeasurement error not only in treatment covariates, but also in treatment times, a\nproblem which arises in practice for example when treatment information is based\non self-reporting. In a challenging and timely problem of estimating the impact of\ndiet on continuous blood glucose measurements, our model leads to signi\ufb01cant\nimprovements in estimation accuracy and prediction.\nKeywords: Treatment-response trajectory \u00b7 Bayesian methods \u00b7 Errors-in-variables\n\u00b7 Hierarchical modeling \u00b7 Gaussian process \u00b7 Wearable self-monitoring devices\n1\nIntroduction\nIncreasing popularity of electronic health records (EHRs) and smart healthcare services\nhas led to accumulation of large quantities of heterogeneous data, with potential to\nconsiderably improve the e\ufb03ciency of clinical practice and health services [34]. This\nhighlights the importance of novel machine learning techniques for EHR data, which can\nbe integrated with mobile apps to provide personalized guidance for purposes ranging\nfrom early diagnosis to support for lifestyle change [12,27]. The latter is speci\ufb01cally\nrelevant to reduce the cost of chronic diseases in the face of the aging population. For\ninstance, the annual economic cost of diabetes in the U.S. is approximately $250 billion\n[1].\nInferring relationships between correlated variables is essential in many \ufb01elds. An\nimportant question is to estimate a patient\u2019s response to a given treatment, comparing\nthe patient\u2019s data from before and after the treatment. A traditional solution is to use\nrandomized controlled trials, which, however may be infeasible due to the cost or ethical\nconsiderations. One possibility is to use mechanistic models, speci\ufb01cally tailored for the\narXiv:1906.03989v1  [cs.LG]  10 Jun 2019\n2\nG. Zhang et al.\nproblem, and use data to learn about their unknown parameters. However, these models\nrequire substantial expert knowledge and are not applicable if the underlying mechanism\nis unknown. On the other hand, data-driven methods, trained on observational EHR data,\nprovide a promising alternative.\nEstimating the impact of a treatment is particularly challenging when the response\nis a continuous curve consisting, for example, of a time-series of measurements of a\nbiological marker. In such cases, the outcome is typically modeled by a Gaussian process\n[35], but also neural networks have been considered [21]. The treatment may either be a\ncontinuous dose function [42], or a discrete event in time [45,41]. The latter approach\nis often relevant in practice when treatments are recorded as discrete events, even if\ntheir true duration is not exactly zero. Treatment data are usually sparse, and hence it\nis essential to share relevant information in a probabilistic model. A latent trajectory\nmodel of [39] uses additive components to explain variation on population and individual\nlevels. Conditional random \ufb01elds can be incorporated to further capture correlations\nbetween di\ufb00erent treatment types [40], and multivariate response curves can be modeled\nby learning latent structure [42] shared across the outcomes.\nDespite increased recent attention, there are still crucial issues in treatment-response\nestimation that have not been addressed when the response is continuous. Most im-\nportantly, the treatments are consistently assumed to be exactly measured and known,\nwhile in reality the treatment input may be severely perturbed by numerous factors.\nThis problem dramatically escalates for user-reported treatment data, which potentially\nresults in complete discredit of the \ufb01ndings [20]. The erroneous e\ufb00ect is two-fold, i.e.,\nin addition to measurement error in covariates, the actual time of the treatment might\nbe known only approximately. Another issue arises from the competing relationship\nbetween a counterfactual trend, i.e., the evolution of the outcome assuming no treatment,\nand the treatment response. When modeled and trained jointly, it easily happens that\na \ufb02exible trend completely overrides the treatment response, and therefore these two\ncomponents are often trained separately in practice.\nTo address the mentioned shortcomings, we introduce errors-in-variables (EIV)\nframework for modeling of continuous treatment-response trajectories. The EIV models\naccount for measurement errors not only in the output variable, as common regression,\nbut also in the inputs [13,14]. They are closely related to latent-variable models in\nmachine learning [28,4], and based on modeling the unobserved true values from which\nnoisy observations are obtained. Our contributions can be summarized as follows:\n\u2013 We formulate an EIV model for personalized treatment-response trajectories, where\na treatment comprises a vector of noisy covariates and treatment times are uncertain.\n\u2013 We introduce an interpretable hierarchical prior on the treatment e\ufb00ects that e\ufb03-\nciently shares information between individuals, and allows training the full model\njointly, appropriately balancing between the trend and the responses.\n\u2013 In a challenging topic, representative of the current technological mega-trend on\nself-monitoring data from wearable devices, we show our method can meaningfully\nestimate the personalized impact of diet on continuous blood glucose measurements.\nThe code and data used in the analyses are available at [link added upon acceptance,\nreviewers can view the material in Supplement] and allow fully reproducing our results.\nErrors-in-variables Modeling of Personalized Treatment-Response Trajectories\n3\n2\nRelated work\nTreatment response: Besides machine learning, the problem of treatment response\nestimation has been studied in various \ufb01elds, including informatics for medicine and\nsocial sciences, where the data-driven approach can bring advantages compared to the\nexperimental trials [30]. For example, individual-level treatment response prediction\nhas been studied for schizophrenia [5] and depression [33]. An empirical comparison\nof classi\ufb01ers for treatment-response prediction for chemoradiotherapy appears in [9].\nTopics studied in social sciences include the e\ufb00ect of a discrete treatment, years of\neducation, on an individuals\u2019 income [6], and allowing a response to depend on social\ninteractions and treatments for other individuals [24].\nMechanistic models: In contrast to the data-driven approaches used in machine\nlearning, mechanistic models use substantial knowledge of a speci\ufb01c problem to charac-\nterize the system with di\ufb00erential equations, and inference is done for example using\n\ufb01ltering algorithms. Similar to our application, [3] and [2] study blood glucose dynamics,\na\ufb00ected by nutrition and other factors. Another example is a computational model of\nthe physiological mechanisms for type-2 diabetes, aiming to quantify factors useful for\nprevention of the disease [37].\nEIV models for treatment response: In contrast to the vast body of research con-\ncerning data-driven methods for the prediction of a treatment response, very little is\nknown about their performance when measurement error is present. Authors of [46]\nstudy a method for inferring causal directions using EIV models, but they do not focus on\nthe response conditioned on speci\ufb01c treatments. Regression on various student covariates,\nincorporating EIV, has been used to predict standardized test scores [22]. In [26], the\ne\ufb00ect of measurement error on a binary treatment response is analyzed, underlining the\ndevastating impact of ignoring such errors. A model for measurement errors has been\nused to quantify uncertainty in order to increase the con\ufb01dence in detecting genuine\ntreatment changes for liver metastases [31].\nNone of these works address the problem of estimating the impact of a multivariate\nvector of covariates on a continuous response with measurement error in covariates and\nuncertainty in treatment timing, the topic of this paper.\n3\nMethods\nIn this section, we \ufb01rst review EIV models on a general level. Then we describe three\nessential components of our model for personalized treatment-response trajectories:\na hierarchical prior on parametric treatment-responses functions, a Gaussian process\nmodel for the trend, and measurement error models. Throughout the section, we present\nthe model in generic terms, but also outline the speci\ufb01c model that we use in Section\n4.2 to estimate the impact of diet, recorded as nutrient contents of di\ufb00erent meals, on\ncontinuous blood glucose measurements.\nOur model is fully Bayesian, yielding uncertainty estimates for all parameters, es-\nsential in scienti\ufb01c applications. Inference is done using Markov chain Monte Carlo\n(MCMC) with the state-of-the-art No-U-Turn (NUTS) sampler [17] implemented in soft-\nware PyMC3 [36]. Implementation details are discussed below and in the supplementary,\nand can be viewed in full in the published code.\n4\nG. Zhang et al.\nX\nX\u2217\nY\u2217\nY\n(a)\nyn\n\u03c3y\nTn\n\u03c4n\n\u03b8Tn\nRnm\nt\u2217\nnm\ndn\nlnm\nhnm\ntnm\nx\u2217\nnm\nxnm\n\u03b2l\nn\n\u03b2h\nn\n\u02dc\u03b2l\n\u02dc\u03b2h\nN\nMn\n(b)\nFig. 1: a) General formulation of the EIV model. For clarity, parameters associated\nwith the distributions are not shown. (b) Model for personalized treatment-response\ntrajectories. Details of the model are discussed in the text.\n3.1\nErrors-in-variables models\nEIV models, a.k.a. measurement error models, are regression or classi\ufb01cation models\nthat, in contrast to most existing models, account for errors not only in the output variable\nbut also in inputs [7,38,15,10]. Though commonly neglected, input mismeasurement\nmay be extremely harmful. For example in simple linear regression it leads to biased\nestimates that can not be corrected for even with an in\ufb01nite sample, while, on the\nother hand, unbiased homoscedastic error in the output variable only induces additional\nvariability [7]. A graphical model for a general EIV model is presented in Figure 1a,\nwhere X\u2217and Y\u2217represent the true values of the inputs and the output, and X and Y are\nthe corresponding noisy observations. The most important type of mismeasurement is\nclassical error, which corresponds to independence of an error term from the true value.\nExcept for the simplest case of linear regression [29], EIV modeling almost always\nrequires auxiliary information or data to correct the mismeasurement bias in estimation.\nFor problems that have an analytical solution, the bias can be corrected by a multiplication\nor addition of external terms [18], e.g., an estimated reliability ratio [7]. For nonlinear\nmodels, auxiliary data, e.g., instrumental variables or repeated measurements, can be\nexploited to help correct bias, e.g., by estimating the density function of the true variable\nErrors-in-variables Modeling of Personalized Treatment-Response Trajectories\n5\nusing a deconvolution technique [38]. However, without additional data, Bayesian EIV\nmodeling is currently the most powerful and \ufb02exible approach, as it allows incorporating\nadditional information in the form of distributional assumptions [15]. In this work, we\nadopt the Bayesian approach.\nMathematically, the measurement error mechanism is de\ufb01ned as the distribution of\nthe noisy observed input, X, given the true unobserved input, X\u2217. The joint distribution\nof the model factorizes accordingly as:\nP(X\u2217, Y\u2217, X, Y, \u0398) = P(X|X\u2217, \u03b8M)P(Y|Y\u2217, \u03b8N)P(Y\u2217|X\u2217, \u03b8R)P(X\u2217|\u03b8E)P(\u0398),\n(1)\nwhere P(X|X\u2217, \u03b8M) and P(Y|Y\u2217, \u03b8N) are called error or measurement models, P(Y\u2217|X\u2217, \u03b8R)\nis a response or outcome model, P(X\u2217|\u03b8E) is an exposure model, and \u0398 = (\u03b8M, \u03b8N, \u03b8R, \u03b8E)\nare the corresponding parameters. Bayes theorem can be used to infer the unknown\nparameters and unobserved true values of the variables.\nP(X\u2217, Y\u2217, \u0398|X, Y) \u221dP(\u0398)\nN\nY\ni\nP(Xi|X\u2217\ni , \u03b8M)P(Yi|Y\u2217\ni , \u03b8N)P(Y\u2217\ni |X\u2217\ni , \u03b8R)P(X\u2217\ni , \u03b8E).\n(2)\nIf the exposure model is noninformative and the measurement model is symmetric, i.e.,\nP(Xi|X\u2217\ni , \u03b8M) = P(X\u2217\ni |Xi, \u03b8M), then the Bayesian modeling of classical error is equivalent\nto another class of mismeasurement techniques know as Berkson error modeling [7].\nP(X\u2217, Y\u2217, \u0398|X, Y) \u221dP(\u0398)\nN\nY\ni\nP(X\u2217\ni |Xi, \u03b8M)P(Yi|Y\u2217\ni , \u03b8N)P(Y\u2217\ni |X\u2217\ni , \u03b8R).\nA well-known di\ufb03culty with EIV models is that they are often nonidenti\ufb01able [15],\ni.e. there are more than one set of values for the unknowns leading to the same model.\nThis can be understood intuitively by noticing that the model stays the same if we\nmultiply the linear regression coe\ufb03cients by a constant factor and at the same time\ndivide the estimated true values of inputs by the same factor. Therefore, to achieve\nidenti\ufb01ability, some crucial information about measurement model has to be assumed\nor estimated, e.g., the variance of a classical additive error in simple linear regression\n[7]. The Bayesian paradigm o\ufb00ers a unique solution to the nonidenti\ufb01ability of the EIV\nmodels, as long as mismeasurement is modest and the prior is su\ufb03ciently good [16].\n3.2\nModel for treatment-response trajectories\nNotation: A graph of our model for treatment-response trajectories is presented in Figure\n1b. We assume there are N patients, and a trajectory consisting of a time series of length\nGn of the outcome (e.g. blood glucose) is observed for each individual:\nyn = (yn1, . . . , ynGn)T, n = 1, . . . , N.\nThese measurements have been taken at times\n\u03c4n = (\u03c4n1, . . . , \u03c4nGn)T, n = 1, . . . , N.\n6\nG. Zhang et al.\nFurthermore, each patient has Mn observed treatments (e.g. meals eaten), indexed by\nm \u22081, . . . , Mn, where each treatment is characterized by P covariates:\nxnm = (xnm1, . . . , xnmP)T, for all m, n,\nand the corresponding recorded treatment times are\ntn = (tn1, . . . , tnMn)T, for all n.\nHere, xnm and tnm are assumed to be noisy observations of the treatment covariates and\ntimings, and their true unobserved values are denoted by x\u2217\nnm and t\u2217\nnm, respectively.\nOutcome model: We model the observed outcome trajectory of individual n, yn, as\nyn = Tn +\nX\nm\nRnm + e,\nwhere Tn \u2208RGn is a counterfactual trend (i.e. it describes the evolution of the outcome\nhad the treatment not been taken), Rnm \u2208RGn is the additive response to the mth\ntreatment, and e = (e1, . . . , eGn)T is the vector of errors with ei \u223cN(0, \u03c32\ny). We note\nthat the sum of the trend and the responses can be viewed as a trajectory for a \u2019clean\u2019\noutcome (omitted from Figure 1b), of which a version yn corrupted by Gaussian noise is\nobserved. Additive response functions can be seen as a continuous extension of scalar\naverage treatment e\ufb00ect (ATE) which is de\ufb01ned as the expected di\ufb00erence of outcomes\nbefore and after treatment.\nResponse function: Response functions specify how treatments a\ufb00ect the outcome\nover time, and they should be speci\ufb01ed to suit the application at hand, balancing \ufb02exibil-\nity, interpretability, etc. For example, if interpretability is not needed and the amount of\ndata is large, non-parametric functions that learn the shape of the response are attractive.\nOn the other hand, parametric functions are suitable when data are scarce, and they are\noften interpretable, which is valuable in itself but also helps specifying prior knowledge\nto improve accuracy. In the application of learning the impact of meals on blood glucose\n(Section 4.2), we model the treatment response using a bell-shaped parametric function\nRnm := f(\u2206nm, hnm, lnm) := hnm exp\n(\u22120.5(\u2206nm \u22123lnm)2\nl2nm\n)\n,\n(3)\nwhere a lag vector \u2206nm = \u03c4n \u2212t\u2217\nnm represents the time since a speci\ufb01c treatment. The\nshape of this response is shown in Figure 2a and it is determined by two parameters\nhnm and lnm with straightforward interpretations: hnm is the height of the response, and\nlnm is the length-scale which is proportional to the \u2019width\u2019 or \u2019duration\u2019 of the response.\nThe main challenge in our application is scarceness and noisiness of data, with only 13\nindividuals and on average 10 meals per patient. We also tried a more \ufb02exible three-\nparameter response used in [41], which allows a skewed response (see Figure 2a), but this\nmodel su\ufb00ered from convergence problems, for which reason we selected the simpler\nalternative.\nIn applications it is often of interest to measure how the response depends on\ntreatment covariates, and therefore we allow these parameters to depend on the covariates:\nhnm = (\u03b2h\nn)Tx\u2217\nnm, and\nlnm = (\u03b2l\nn)Tx\u2217\nnm, for all n, m.\n(4)\nErrors-in-variables Modeling of Personalized Treatment-Response Trajectories\n7\nIn Equation (4), the coe\ufb03cient vectors \u03b2h\nn, \u03b2l\nn \u2208RP represent the personalized impact of\neach of the P covariates on the height or width of the response for the nth individual.\nTo share information across individuals, we introduce a Bayesian hierarchical prior, see\n[11], and assume that the personalized height and length-scale coe\ufb03cients, \u03b2h\nn and \u03b2l\nn,\nare drawn from common distributions:\n\u03b2h\nn \u223cNP(\u02dc\u03b2h, \u03a3h)\nand\n\u03b2l\nn \u223cNP(\u02dc\u03b2l, \u03a3l).\nA hyperprior is further placed on the mean parameters of these distributions:\n\u02dc\u03b2h \u223cNP(0, \u02dc\u03a3h)\nand\n\u02dc\u03b2l \u223cNP(0, \u02dc\u03a3l)\nThe hierarchical prior introduces shrinkage and facilitates estimation of the personalized\ncoe\ufb03cients with limited data. Further details are given in the Supplementary material.\nCounterfactual trend: A counterfactual trend represents the outcome assuming no\ntreatment has been taken. It has to be su\ufb03ciently \ufb02exible to handle any variation in the\noutcome that is not accounted for by the treatments. In this paper, we model the trend\nTn(t) for individual n using a Gaussian Process (GP) [35]:\nTn(t) \u223cGP(0, k(t, t\u2032|\u03b8Tn)),\nwhere \u03b8Tn are parameters associated with the kernel function k(x, x\u2032|\u03b8Tn). GPs are non-\nparametric regression models with well-known closed-form formulas for posterior esti-\nmation, which they inherit from the Normal distribution by assuming all training and\ntest data follow a joint Normal distribution. For example, if\nSn = yn \u2212\nX\nm\nRnm\nis the residual of the outcome after subtracting the impact of the treatment responses,\nthen\nTn(t)|Sn \u223cN(\u00b5\u2217, \u03a3\u2217),\nwhere\n\u00b5\u2217= k(\u03c4n, t)T K(\u03c4n, \u03c4n)\u22121Sn,\nand\n\u03a3\u2217= k(t, t) \u2212k(\u03c4n, t)T K(\u03c4n, \u03c4n)\u22121k(\u03c4n, t).\nWe refer the reader to [35] for more details about GPs. As the kernel, we use the sum of\nSquared Exponential (SE) and constant kernels, where the former equips the GP with\ndesired smoothness, and the latter enables meaningful extrapolation to regions where\nno input points have been observed. To speed up computation, we use a sparse GP\n[35] instead of a full GP, which samples a small set of inducing points uniformly from\n\u03c4n to achieve a low-rank approximation of K(\u03c4n, \u03c4n) and its inverse. A detailed prior\nspeci\ufb01cation is provided in the Supplementary material.\nMeasurement models: Measurement models describe error in observations. With\nself-reported data both covariates and the timing of a treatment may be uncertain. To\naccount for the uncertainty in treatment timing, we assume:\ntnm \u223cN(t\u2217\nnm + dn, (\u03c3t\nn)2),\nfor all n, m.\n8\nG. Zhang et al.\nIn words, the observed time tnm is obtained from the true time t\u2217\nnm by shifting it with a\nbias term dn, and adding Gaussian noise. The bias term dn represents reporting habits of\ndi\ufb00erent individuals. For example, in the blood glucose application in Section 4.2, some\nindividuals may systematically report their meal after eating, while others may do this\nbefore eating.\nDi\ufb00erent models are possible for treatment covariates, depending on the assump-\ntions and data available [15]. Here we assume a simple perturbation on the amount of\ntreatment:\nxnm = x\u2217\nnm\u03b4nm,\nwhere\n\u03b4nm \u223cLogNormal(0, \u03c32\nx),\nfor all n, m.\n(5)\nThe coe\ufb03cient \u03b4nm represents the error in the mth treatment of the nth individual. Intuition\nin the blood glucose application is that users are able to report correctly what they have\neaten, but not how much. While the model (5) captures our understanding of the type of\nmismeasurement expected in our data, more complicated models could also be justi\ufb01ed,\nbut they would require stronger additional assumptions to resolve the nonidenti\ufb01ability\nof the EIV models. The model in (5) is identi\ufb01able and can be trained with relatively\nlittle data, as we demonstate in Section 4.\nEstimating t\u2217\nnm is straightforward as it only shifts the response, but does not change\nits shape. However, estimating x\u2217\nnm is more complicated, and requires assuming that\nthe counterfactual trend is su\ufb03ciently regularized. Otherwise the trend could easily\ncompensate for the perturbation. We solve this by encouraging a large length-scale for\nthe squared exponential kernel in the prior. Further details, e.g., prior distributions for\nx\u2217\nnm, t\u2217\nnm, and dn, are provided in the Supplementary material.\n3.3\nA note on causality\nWe brie\ufb02y review results related to estimation of causal e\ufb00ects from observational data\non treatment-response trajectories [32,25,41], to enable a user of our method to judge to\nwhat extent the e\ufb00ects found may or may not be interpreted causally. The causal e\ufb00ect\nof an action A (e.g. a treatment) on Y is de\ufb01ned as P(Y = y|do(A = a)), where the do(\u00b7)\noperator represents a manipulation of A to value a. The key assumption is that there are\nno unmeasured confounders (NUC), such as Z2 in Figure 2b. Without Z2, the causal\ne\ufb00ect of A on Y can be estimated from observational data using the adjustment formula:\nP(Y = y|do(A = a)) =\nX\nz1\nP(Y = y|A = a, Z1 = z1)P(Z1 = z1).\nTime-varying treatments (Figure 2c) further face an issue of treatment-confounder\nfeedback [25], which means that hidden confounders do not have to a\ufb00ect A directly to\ncreate a spurious correlation between an action and future observations. A generalized\nadjustment formula, g-formula, can still be used to calculate P( \u00afY\u2265t|do(At\u22121, At)), see [8].\nA useful result, applicable with our model, is to use the model to estimate P( \u00afY\u2265t| \u00afA\u2264t, \u00afY<t)\nfrom observational data. Then, assuming NUC, the following holds [25]:\nP( \u00afY\u2265t|do(At), \u00afA<t, \u00afY<t) = P( \u00afY\u2265t| \u00afA\u2264t, \u00afY<t).\n(6)\nErrors-in-variables Modeling of Personalized Treatment-Response Trajectories\n9\n0\n50\n100\n150\n200\n250\n300\nTime\n0.0\n0.2\n0.4\n0.6\n0.8\n1.0\nUnscaled height\nheight\nlength scale\nbell\nexpdiff\n(a)\nA\nY\nZ1\nZ2\n(b)\nYt\u22121\nYt\nYt+1\nAt\nAt\u22121\nZt\u22121\nZt\nZt+1\n(c)\nFig. 2: a) Two Response functions. The blue one is used in this paper, while the orange\none is used in [41], (b) Graphical model for a cross-sectional case, showing action\n(A), response (Y), and observed and hidden confounders (Z1 and Z2), and (c) over-time\nresponse with a single treatment, where confounders Z can be either observed or hidden.\nIn words, conditionally on the history of treatments and the outcome (and relevant\nobserved confounders not shown in the formula), the causal impact of the most recent\ntreatment on future outcomes can be estimated from observational data. This short-term\ne\ufb00ect can be used, e.g., to select between alternative treatments available at a certain\npoint in time, when the relevant history of the individual is known.\nIn Section 4.2 we analyse the impact of diet on blood glucose. Based on domain\nknowledge, we know that diet is a prominent cause of changes in blood glucose. Fur-\nthermore, in our data we often see a rapid increase and decrease in blood glucose after a\nmeal. Therefore, it seems plausible that meals a\ufb00ect blood glucose causally. However,\nin general, the causal assumptions can not be veri\ufb01ed from observational data, and it\nis possible that some confounder a\ufb00ects both glucose and diet, but the e\ufb00ect of any\nsuch confounder is expected to be small compared to the impact of diet. Hence, while\ninterpreting our results causally seems reasonable, we can not make assertions of this.\nMore generally, with emergence of modern wearable self-monitoring devices, it will\nbe possible to measure all relevant factors that could a\ufb00ect blood glucose much more\ncomprehensively, and the NUC assumption is reasonable. Our model is straightforward\nto extend to such data.\n4\nExperiments\nIn this section, we \ufb01rst examine identi\ufb01ability and accuracy of our model using simulated\ndata, and then use it to analyze a real-world dataset comprising diet and continuous\nblood glucose measurements. Throughout, we compare four models, in an increasing\norder of complexity (later models include the previous as special cases):\n\u2013 Mind : Separate models for individuals.\n\u2013 Mhier : Model with the hierarchical prior for the responses to share information\nacross individuals.\n10\nG. Zhang et al.\n\u2013 Mhier+time : Time uncertainty included.\n\u2013 Mhier+time+cov : Uncertainty in covariates included.\n4.1\nIdenti\ufb01ability and accuracy of the models on simulated datasets\nAs a simple experiment, we \ufb01rst study the identi\ufb01ability of the EIV model when there\nis measurement error in the covariates. We simulate arti\ufb01cial data using a toy model\nspeci\ufb01ed as the sum of a linear trend and the parametric treatment response from\nEquation (3). The dimension of treatment covariates is here set to 2, and each input\nis perturbed with an additive term drawn from N(1, 0.22). We analyze the data using\nthe EIV model that assumes measurement error, and a model that disregards the noise\nin the covariates. Results and further details for this simple setup are presented in the\nSupplementary material, and they show that the EIV model recovers all true inputs and\ne\ufb00ect sizes with high accuracy, while the model that neglects the noise leads to biased\ncoe\ufb03cient estimates with wide con\ufb01dence intervals.\nTo study the accuracy and identi\ufb01ability of our method in a more realistic simulated\nsetup, we \ufb01rst \ufb01t our model to the real-world data from Subsection 4.2, and use the \ufb01tted\nmodel to simulate responses and trends for two individuals. We perturb half of the inputs\naccording to Equation (5) and let the model use the perturbed inputs and try to recover\nthe true inputs and parameters. The performance of all models depends on the relative\ncontributions of the trend and responses, and we scale up the response with a factor of 5,\nwhich facilitates a meaningful comparison.\n0.7\n0.8\n0.9\n1.0\n1.1\n1.2\n1.3\n1.4\nPerturbation Rates\ntr01\ntr02\ntr03\ntr04\ntr05\ntr06\ntr07\ntr08\ntr09\ntr10\ntr11\ntr12\ntr13\nTreatments\nhier + time + cov\nperturbed\nSTARCH\nSUGAR\nFIBC\nFAT\nPROT\nCoef Dimension\n0.75\n0.50\n0.25\n0.00\n0.25\n0.50\n0.75\nHeight Coef\ntrue\nhier + time + cov\nhier + time\nhier\n0.00\n0.05\n0.10\n0.15\n0.20\n0.25\n0.30\n0.35\n0.40\nPerturbation Rates\n0.70\n0.75\n0.80\n0.85\n0.90\n0.95\n1.00\nSimilarity against Height Coef\nhier + time + cov0.1\nhier + time + cov0.2\nhier + time\nhier\nFig. 3: Simulation results. Left: true and estimated perturbations for one individual (the\nother one shown in Supplement); Center: true and estimated coe\ufb03cients for the height of\nthe response for 5 covariates; Right: Cosine similarity of concatenated height coe\ufb03cient\nvectors from all individuals against the true value with di\ufb00erent levels of perturbation\n(higher value is better). Two di\ufb00erent prior SDs, 0.1 and 0.2, were considered for model\nMhier+time+cov.\nResults for one individual are shown in Figure 3, and for the other in the Supple-\nmentary material. We see that the direction of each non-zero perturbation is estimated\ncorrectly (left panel), and this is true also for the other individual (Supplementary). On\nthe other hand, if there is no perturbation, the model may even then estimate non-zero\nperturbations, introducing additional noise. This re\ufb02ects the trade-o\ufb00between \ufb02exibility\nand over\ufb01tting, and highlights the importance of carefully validating the model to suit the\nErrors-in-variables Modeling of Personalized Treatment-Response Trajectories\n11\namount and complexity of data. We also see that the regression coe\ufb03cients are estimated\naccurately by the EIV model (center), and that the bene\ufb01t from using EIV becomes more\nsigni\ufb01cant when the size of the perturbation increases (right). However, a too loose EIV\nprior (large SD) may actually harm the performance by introducing additional noise,\nwhen the true perturbation is small.\n4.2\nExperiments on real-world glucose data\nThe data contain blood glucose measurements and dietary records. These anonymized\ndata were provided by the Obesity Research Unit at the University of Helsinki, Fin-\nland, and they are available for 13 non-diabetic individuals across three days. Diabetic\nindividuals were excluded because their metabolism di\ufb00ers extensively from healthy\nindividuals, and detailed modeling of that is beyond the scope of this work. The real-\nvalued blood glucose measurements were collected by a portable continuous glucose\nmonitoring system approximately every \ufb01fteen minutes. The dietary records consist of\nuser-reported contents and times of all meals eaten during the 3-day study period. Each\nmeal has been processed into amounts of \ufb01ve nutrients: starch, sugar, \ufb01ber, fat, and\nprotein. The goal of the analysis is to learn how these nutrients in\ufb02uence blood glucose.\nBoth the exact amounts of food eaten and the exact meal times are uncertain, as they are\nbased on values estimated and reported by users, which motivates the use of EIV models\nfor these data. A visualization of the data (and results) for one individual is shown in\nFigure 4, and for all other individuals in the Supplement. Some markers may be missing\ndue to device errors or when a user has removed the device.\nFig. 4: Visualization of the 3-day time series for one patient. Red and brown dots\nrepresent glucose markers in the training and test sets, respectively. Meals are indicated\nby vertical bars, colored according to amounts of di\ufb00erent nutrients in the meal. The\ngreen curve is the \ufb01nal \ufb01tted trajectory, and it is a combination of the dashed blue line, a\ncounterfactual trend, and the mean of red lines, which are posterior samples of treatment\nresponses. Horizontal arrows associated with the meals show the estimated di\ufb00erence\nbetween true and observed meal times.\nMetrics: The models are trained using data from the \ufb01rst two days, and the third day\nis used for testing. The performance of treatment-response estimation is quanti\ufb01ed using\n\ufb01ve metrics Mi, i \u2208{1, . . . , 5}. M1 is the proportion of variance explained by the trend:\nM1 = 1\nN\nX\nn\nVar(Tn)\nVar(yn) .\n12\nG. Zhang et al.\nM2 indicates how much more is explained when also the treatment responses are in-\ncluded:\nM2 = 1\nN\nX\nn\nVar(Tn + P\nm Rnm)\nVar(yn)\n\u2212M1.\nIn detail, a large M1 means that the outcome is mostly explained by the trend, and a small\nM2 represents an inactive treatment response. These metrics are computed in regions of\nnon-zero treatment response. Metrics M3 and M4 are simply the mean squared errors in\nthe training and test data. They are calculated for all individuals for whom M2 indicates\nthat the response has been properly learned. Thus one patient, shown in Figure 5, with\nM2 \u22480.05 for the baseline model Mhier is excluded from MSE calculations (other\npatients have M2 > 0.3).\nBecause M4 measures pointwise error, it may be misleadingly low when the response\nshape is correct if its location is inaccurate. Metric M5 is insensitive to the inaccuracy of\nlocation, and it measures the absolute error in variance between predicted response and\noutcome:\nM5 = 1\nN\nX\nn\n|Var\n\u0010 X\nm\nRnm\n\u0011\n\u2212Var(yn)|\nBecause our interest is in estimation of the treatment response, and not the trend, we\ncalculate M4 and M5 in windows from one hour before to three hours after each meal.\nWe use the Mann\u2013Whitney U-test [23] to test if other models are better than Mhier\nin terms of test error M4. The reason for using Mhier as the baseline is the main\nargument of this article that EIV modeling is bene\ufb01cial when estimating treatment-\nresponse trajectories, and Mhier is otherwise the same as Mhier+time and Mhier+time+cov\nexcept that it the does not include the EIV components. We also compare the models\nusing an information criterion for predictive accuracy. The state-of-the-art criterion is\nleave-one-out cross-validation (LOO) [43], which is used here.\nM1\nPVE\nTrend\nM2\nPVE\nResp\nM3\nMSE\nTrain\nM4\nMSE\nTest\nM5\n\u2206Var\nTest\np-value\nU-test\nLOO\npLOO\nSE\nLOO\nMind\n0.361\n0.342\n0.149\n1.695\n0.927\n1.00\n3549.64 246.64\n318.8\nMhier\n0.359\n0.339\n0.159\n0.752\n0.391\n-\n3587.87 214.62 317.28\nMhier+time\n0.350\n0.424\n0.098\n0.738\n0.377\n3.24e-4 2869.91 342.24 265.09\nMhier+time+cov 0.344\n0.428\n0.098\n0.743\n0.366\n4.66e-3 2994.98 465.47\n333.7\nTable 1: Comparison of models using the real-world glucose data. The metrics M1\nthrough M5 are de\ufb01ned in text, where PVE means Proportion of Variance Explained.\np-value tests if other models are better than Mhier in terms of M4. LOO stands for\nleave-one-out cross-validation, pLOO is the estimated e\ufb00ective number of parameters,\nand SE-LOO records the standard error in the LOO computations.\nResults: Result are shown in Table 1. We see that all models outperform the non-\nhierarchical baseline Mind by a large margin. Furthermore, taking treatment time in-\naccuracy into account in Mhier+time improves signi\ufb01cantly over the non-EIV model\nErrors-in-variables Modeling of Personalized Treatment-Response Trajectories\n13\nMhier. In fact, estimation of the response fails completely for some individuals without\ntime EIV; the results with and without time uncertainty modeling for one such case are\nshown in Figure 5. On the other hand, taking uncertainty in covariates into account does\nnot notably improve accuracy, which is likely caused by a combination of increased\n\ufb02exibility and limited amount of data. Overall, models with EIV component outperform\nthe model without EIV in all metrics.\nFig. 5: Demonstration of time uncertainty modeling for one individual. Upper: Results\nusing Mhier+time, where arrows indicate the estimated di\ufb00erence between the true and\nobserved meal times; Bottom: Results using Mhier.\nInterpretability of personalized treatment response is also of great interest; for\ninstance, understanding how an individual\u2019s glucose level changes if she eats one more\nunit of sugar. The overall goal of glucose monitoring is to keep the glucose level in\na given range, and both the amount of excess and the duration of the hyperglycemic\nstate are clinically important. Hence, a sensible parameter to consider is the impact of\ndi\ufb00erent nutrients on the area of the response curve. Though this is not a parameter\nof our model, it is straightforward to derive the personalized increase in response area\ndue to one unit increase of a speci\ufb01c nutrient \u2206Anp (n \u22081, . . . , N, p \u2208{1...P}), using\ncoe\ufb03cients for height and width, which are modeled explicitly (see Supplement).\nOverall, starch and sugar have the strongest positive impact on glucose (Figure\n6a), consistent with the understanding that carbohydrates increase blood glucose [44].\nProtein, on the other hand, has a negative impact, which has been observed before and\nmight represent a complex short-term interaction between nutrients [19]. An advantage\nof our model is that we get personalized coe\ufb03cients for each individual, as shown for\nstarch in Figure 6b, and for the other nutrients in the Supplement. Finally, posterior\nuncertainty of personalized starch coe\ufb03cients is shown in Figure 6c. Importantly, models\nwith EIV have much narrower con\ufb01dence intervals, meaning that they are estimated\nmore accurately, thanks to increased \ufb02exibility that allows \ufb01tting the complex data.\n14\nG. Zhang et al.\nMean Std\nSTARCH\n9.57\n4.29\nSUGAR\n6.36\n4.97\nFIBC\n2.83\n4.95\nFAT\n5.29\n5.49\nPROT\n\u221210.13\n3.90\n(a)\n0\n10\n20\nGlucose Area Increment by STARCH\n0\n1\n2\n3\n4\nNumber of Patients\n(b)\n(c)\nFig. 6: a). Average impact on response area \u2206Anp by di\ufb00erent nutrients; b) Histogram\nof personalized starch coe\ufb03cients and their mean (+/- one SD) (red); c) Posterior\nuncertainty in the personalized starch coe\ufb03cients.\n5\nConclusion\nWe presented a hierarchical model with EIV components to estimate personalized\ntreatment-response trajectories when the covariates and timing of a treatment are impre-\ncise. Our model demonstrates superior performance in both simulated and real-world\ndata on various metrics, and allows extracting interpretable and meaningful estimates\nof the personalized impacts of treatment covariates, valuable in applications. Future\ndirections include extensions and identi\ufb01ability of EIV modelling, and extending the\nmodel to include interactions between covariates and other unmeasured confounders,\nsuch as physical activity, for causal completeness.\nReferences\n1. ADA: Economic costs of diabetes in the U.S. in 2012. Diabetes Care 36(4), 1033\u20131046\n(March 2013). https://doi.org/10.2337/dc12-2625, American Diabetes Association\n2. Albers, D.J., Levine, M., Gluckman, B., Ginsberg, H., Hripcsak, G., Mamykina, L.: Person-\nalized glucose forecasting for type 2 diabetes using data assimilation. PLoS computational\nbiology 13(4), e1005232 (2017)\n3. Balakrishnan,\nN.P.,\nSamavedham,\nL.,\nRangaiah,\nG.P.:\nPersonalized\nmechanistic\nmodels for exercise, meal and insulin interventions in children and adolescents\nwith\ntype\n1\ndiabetes.\nJournal\nof\nTheoretical\nBiology\n357,\n62\n\u2013\n73\n(2014).\nhttps://doi.org/https://doi.org/10.1016/j.jtbi.2014.04.038\n4. Bishop, C.M.: Pattern Recognition and Machine Learning. Springer-Verlag, Berlin, Heidelberg\n(2006)\n5. Cao, B., Cho, R.Y., Chen, D., Xiu, M., Wang, L., Soares, J.C., Zhang, X.Y.: Treat-\nment response prediction and individualized identi\ufb01cation of \ufb01rst-episode drug-na\u00a8\u0131ve\nschizophrenia using brain functional connectivity. Molecular Psychiatry (June 2018).\nhttps://doi.org/10.1038/s41380-018-0106-5\n6. Card, D.: The causal e\ufb00ect of education on earnings. In: Handbook of Labor Economics, vol.\n3, Part A, chap. 30, pp. 1801\u20131863. Elsevier, 1 edn. (1999)\n7. Carroll, R.J., Ruppert, D., Crainiceanu, C.M., Stefanski, L.A.: Measurement error in nonlinear\nmodels: a modern perspective. Chapman and Hall/CRC (2006)\nErrors-in-variables Modeling of Personalized Treatment-Response Trajectories\n15\n8. Daniel, R.M., Cousens, S., De Stavola, B., Kenward, M.G., Sterne, J.: Methods for dealing\nwith time-dependent confounding. Statistics in medicine 32(9), 1584\u20131618 (2013)\n9. Deist, T.M., Dankers, F.J.W.M., Valdes, G., Wijsman, R., Hsu, I.C., Oberije, C., Lust-\nberg, T., van Soest, J., Hoebers, F., Jochems, A., El Naqa, I., Wee, L., Morin, O., Raleigh,\nD.R., Bots, W., Kaanders, J.H., Belderbos, J., Kwint, M., Solberg, T., Monshouwer, R.,\nBussink, J., Dekker, A., Lambin, P.: Machine learning algorithms for outcome prediction\nin (chemo)radiotherapy: An empirical comparison of classi\ufb01ers. Medical Physics 45(7),\n3449\u20133459 (2018). https://doi.org/10.1002/mp.12967\n10. Fuller, W.: Measurement Error Models. Wiley, New York (1987)\n11. Gelman, A., Stern, H.S., Carlin, J.B., Dunson, D.B., Vehtari, A., Rubin, D.B.: Bayesian data\nanalysis. Chapman and Hall/CRC (2013)\n12. Ghassemi, M., Naumann, T., Schulam, P., Beam, A.L., Ranganath, R.: Opportunities in\nmachine learning for healthcare. CoRR abs/1806.00388 (2018), http://arxiv.org/abs/\n1806.00388\n13. Griliches, Z.: Errors in Variables and Other Unobservables. Econometrica 42(6), 971\u2013998\n(November 1974), https://ideas.repec.org/a/ecm/emetrp/v42y1974i6p971-98.\nhtml\n14. Griliches, Z., Hausman, J.A.: Errors in variables in panel data. Journal of Econometrics 31(1),\n93 \u2013 118 (1986). https://doi.org/https://doi.org/10.1016/0304-4076(86)90058-8\n15. Gustafson, P.: Measurement Error and Misclassi\ufb01cation in Statistics and Epidemiology:\nImpacts and Bayesian Adjustments. CRC Press, New York, 1 edn. (2004)\n16. Gustafson, P., Le, N.D., Saskin, R.: Case-control analysis with partial knowledge of exposure\nmisclassi\ufb01cation probabilities. Biometrics 57(2), 598\u2013609 (2001)\n17. Ho\ufb00man, M.D., Gelman, A.: The No-U-turn sampler: adaptively setting path lengths in\nHamiltonian Monte Carlo. Journal of Machine Learning Research 15(1), 1593\u20131623 (2014)\n18. Hwang, J.T.: Multiplicative errors-in-variables models with applications to recent data released\nby the us department of energy. Journal of the American Statistical Association 81(395), 680\u2013\n688 (1986)\n19. Karamanlis, A., Chaikomin, R., Doran, S., Bellon, M., Bartholomeusz, F.D., Wishart, J.M.,\nJones, K.L., Horowitz, M., Rayner, C.K.: E\ufb00ects of protein on glycemic and incretin responses\nand gastric emptying after oral glucose in healthy subjects. The American Journal of Clinical\nNutrition 86(5), 1364\u20131368 (November 2007). https://doi.org/10.1093/ajcn/86.5.1364\n20. Kreider, B.: Regression coe\ufb03cient identi\ufb01cation decay in the presence of infrequent classi\ufb01-\ncation errors. The Review of Economics and Statistics 92(4), 1017\u20131023 (2010)\n21. Lim, B.: Forecasting treatment responses over time using recurrent marginal structural net-\nworks. In: Advances in Neural Information Processing Systems. pp. 7494\u20137504 (2018)\n22. Lockwood, J.R., McCa\ufb00rey, D.F.: Correcting for test score measurement error in ANCOVA\nmodels for estimating treatment e\ufb00ects. Journal of Educational and Behavioral Statistics\n39(1), 22\u201352 (2014). https://doi.org/10.3102/1076998613509405\n23. Mann, H.B., Whitney, D.R.: On a test of whether one of two random variables is stochastically\nlarger than the other. The annals of mathematical statistics pp. 50\u201360 (1947)\n24. Manski, C.F.: Identi\ufb01cation of treatment response with social interactions. The Econometrics\nJournal 16(1), S1\u2013S23 (2013). https://doi.org/10.1111/j.1368-423X.2012.00368.x\n25. Miguel A. Hern\u00b4an, J.M.R.: Causal inference (2018), preprint on webpage at https://www.\nhsph.harvard.edu/miguel-hernan/causal-inference-book/s\n26. Millimet, D.: The elephant in the corner: A cautionary tale about measurement error in\ntreatment e\ufb00ects models. IZA Discussion Papers 5140, Institute for the Study of Labor (IZA)\n(2010)\n27. Miotto, R., Wang, F., Wang, S., Jiang, X., Dudley, J.T.: Deep learning for healthcare: re-\nview, opportunities and challenges. Brie\ufb01ngs in Bioinformatics 19(6), 1236\u20131246 (2018).\nhttps://doi.org/10.1093/bib/bbx044\n16\nG. Zhang et al.\n28. Murphy, K.P.: Machine learning: a probabilistic perspective. MIT Press, 1 edn. (Aug 2013)\n29. Pal, M.: Consistent moment estimators of regression coe\ufb03cients in the presence of errors in\nvariables. Journal of Econometrics 14(3), 349\u2013364 (1980)\n30. Passos, I.C., Mwangi, B.: Machine learning-guided intervention trials to predict treatment\nresponse at an individual patient level: an important second step following randomized clinical\ntrials. Molecular Psychiatry (September 2018). https://doi.org/10.1038/s41380-018-0250-y\n31. Pathak, R., Ragheb, H., Thacker, N.A., Morris, D.M., Amiri, H., Kuijer, J., deSouza, N.M.,\nHeerschap, A., Jackson, A.: A data-driven statistical model that estimates measurement uncer-\ntainty improves interpretation of adc reproducibility: a multi-site study of liver metastases.\nScienti\ufb01c Reports 7(1), 14084\u201314094 (2017). https://doi.org/10.1038/s41598-017-14625-0\n32. Pearl, J.: Causality. Cambridge university press (2009)\n33. Pearson, R., Pisner, D., Meyer, B., Shumake, J., Beevers, C.G.: A machine learning ensemble\nto predict treatment outcomes following an internet intervention for depression. Psychological\nMedicine p. 1\u201312 (2018). https://doi.org/10.1017/S003329171800315X\n34. Powell, J., Buchan, I.: Electronic health records should support clinical research. Journal of\nmedical Internet research 7(1), 93 \u2013 118 (2005). https://doi.org/10.2196/jmir.7.1.e4\n35. Rasmussen, C.E.: Gaussian processes in machine learning. In: Advanced lectures on machine\nlearning, pp. 63\u201371. Springer (2004)\n36. Salvatier, J., Wiecki, T.V., Fonnesbeck, C.: Probabilistic programming in Python using PyMC3.\nPeerJ Computer Science 2, e55 (2016)\n37. Sarkar, J., Dwivedi, G., Chen, Q., Sheu, I.E., Paich, M., Chelini, C.M., D\u2019Alessandro,\nP.M., Burns, S.P.: A long-term mechanistic computational model of physiological factors\ndriving the onset of type 2 diabetes in an individual. PLOS ONE 13(2), 1\u201337 (02 2018).\nhttps://doi.org/10.1371/journal.pone.0192472\n38. Schennach, S.M., Hu, Y., Lewbel, A.: Nonparametric identi\ufb01cation of the classical errors-in-\nvariables model without side information. Tech. rep., cemmap working paper (2007)\n39. Schulam, P., Saria, S.: A framework for individualizing predictions of disease trajectories by\nexploiting multi-resolution structure. In: Advances in Neural Information Processing Systems.\npp. 748\u2013756 (2015)\n40. Schulam, P., Saria, S.: Integrative analysis using coupled latent variable models for individu-\nalizing prognoses. The Journal of Machine Learning Research 17(1), 8244\u20138278 (2016)\n41. Schulam, P., Saria, S.: Reliable decision support using counterfactual models. In: Advances in\nNeural Information Processing Systems. pp. 1697\u20131708 (2017)\n42. Soleimani, H., Subbaswamy, A., Saria, S.: Treatment-response models for counterfac-\ntual reasoning with continuous-time, continuous-valued interventions. arXiv preprint\narXiv:1704.02038 (2017)\n43. Vehtari, A., Gelman, A., Gabry, J.: Practical Bayesian model evaluation using leave-one-out\ncross-validation and WAIC. Statistics and Computing 27(5), 1413\u20131432 (2017)\n44. Wolever, T.M., Miller, J.B.: Sugars and blood glucose control. The American Journal of\nClinical Nutrition 62(1), 212S\u2013221S (July 1995). https://doi.org/10.1093/ajcn/62.1.212s\n45. Xu, Y., Xu, Y., Saria, S.: A non-parametric bayesian approach for estimating treatment-\nresponse curves from sparse time series. In: Proceedings of the 1st Machine Learning for\nHealthcare Conference. vol. 56, pp. 282\u2013300 (August 2016)\n46. Zhang, Y., Luo, G.: Inferring causal directions in errors-in-variables models. In: Proceedings\nof the Twenty-Eighth AAAI Conference on Arti\ufb01cial Intelligence (July 2014)\n"}