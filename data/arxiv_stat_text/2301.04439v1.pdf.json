{"text": "arXiv:2301.04439v1  [econ.EM]  11 Jan 2023\nUniform Inference in Linear\nError-in-Variables Models:\nDivide-and-Conquer\nTom Boot\u2217\nArt\u00afuras Juodis\u2020\nJanuary 12, 2023\nAbstract\nIt is customary to estimate error-in-variables models using higher-\norder moments of observables. This moments-based estimator is con-\nsistent only when the coe\ufb03cient of the latent regressor is assumed to\nbe non-zero. We develop a new estimator based on the divide-and-\nconquer principle that is consistent for any value of the coe\ufb03cient of\nthe latent regressor. In an application on the relation between invest-\nment, (mismeasured) Tobin\u2019s q and cash \ufb02ow, we \ufb01nd time periods\nin which the e\ufb00ect of Tobin\u2019s q is not statistically di\ufb00erent from zero.\nThe implausibly large higher-order moment estimates in these periods\ndisappear when using the proposed estimator.\nJEL codes: C21, C23, E22, G31.\nKeywords: error-in-variables, divide-and-conquer, uniform inference.\nWord count: 7349.\n\u2217Corresponding author. University of Groningen, t.boot@rug.nl\n\u2020University of Amsterdam and Tinbergen Institute, a.juodis@uva.nl.\n1\n1\nIntroduction\nTo account for measurement error in independent variables, higher-order\nmoment estimators have been used to analyse the relation between R&D\nexpenditures and patent applications (Lewbel, 1997), to test the q-theory of\ninvestment in \ufb01nance (Erickson and Whited, 2000), and to investigate \ufb01rm\nsaving behaviour (Riddick and Whited, 2009). Underlying these estimators\nare two crucial assumptions: \ufb01rst, there needs to be su\ufb03cient skewness in the\nlatent regressor. Second, the coe\ufb03cient \u03b20 that relates the latent regressor\nto the observed outcome cannot equal zero. In this paper we focus on the\nsituation where this second assumption potentially fails. In particular, we\nconsider the standard third-order moment estimator that can be attributed to\nGeary (1942). When \u03b20 = 0, this estimator converges to a ratio of correlated\n(mean zero) normal random variables.\nAs a solution to this problem, we propose an estimator based on a divide-\nand-conquer strategy: the data is split into equal sized blocks. In each block,\nwe calculate the denominator and numerator of the estimator (by Geary,\n1942) on non-overlapping subsets of the data. This breaks the dependency\nbetween the numerator and denominator, and ensures that the estimator\nis median unbiased regardless of the value of \u03b20. Subsequently taking the\nmedian over the estimators from the di\ufb00erent blocks yields a consistent and\nasymptotically normal estimator irrespective of the value of \u03b20. However,\nthe rate of convergence of the proposed estimator depends on the number of\nblocks when \u03b20 = 0 and increases to the standard rate when \u03b20 \u0338= 0.\nTo test the proposed estimator in practice, we revisit an empirical test of\ncorporate \ufb01nance\u2019s q-theory. This theory states that investment \ufb02uctuations\nare driven by the marginal q: the market value of capital relative to the\nshadow value of capital.1 Empirically, q-theory appeared discredited with for\nexample Blundell et al. (1992) \ufb01nding a signi\ufb01cant role for internals funds\nafter controlling for q.\nHowever, Erickson and Whited (2000) show that\nthese \ufb01ndings can be explained by the substantial measurement error in\nTobin\u2019s q measure of marginal q. This measurement error drives down the\n1An overview of the history of q-theory can be found in Erickson and Whited (2000)\n2\nestimated coe\ufb03cient on q, while increasing the coe\ufb03cient of controls such as\ninternal funds. Accounting for measurement error via the use of higher-order\nmoment estimators showed that q-theory is not at odds with the data, see\nalso Erickson and Whited (2012) and Andrei et al. (2019).\nWe \ufb01rst consider the simulation set-up of Erickson et al. (2014), which\nis geared to the environment in which q-theory can be tested. We \ufb01nd that\nthe divide-and-conquer estimator performs well regardless of the value of \u03b20,\nunlike the third-order moment estimator that is ill-de\ufb01ned when \u03b20 = 0.\nWe then analyse the data on \ufb01rm investment, Tobin\u2019s q and cash \ufb02ow\nfrom Erickson et al. (2014). When using the full sample of available data,\nranging from 1970 to 2011, the divide-and-conquer estimates are in line with\nthose in Erickson et al. (2014). In particular, we do not \ufb01nd evidence for the\ne\ufb00ect of cash \ufb02ow on \ufb01rm investment. Motivated by the notion of Erickson\net al. (2014) that there exists variation over time in the estimates, we then re-\nestimate the coe\ufb03cients using an expanding window of data starting with the\ndata in 1970-1980 and ending with the full sample 1970-2011. We indeed \ufb01nd\nsubstantial changes in the estimated relation between investment, Tobin\u2019s q\nand cash \ufb02ow over time. In particular, we \ufb01nd rather extreme point estimates\nand con\ufb01dence intervals in time periods before the mid-1980s. These occur\nprecisely in time periods in which the divide-and-conquer estimator is not\nsigni\ufb01cantly di\ufb00erent from zero. The divide-and-conquer estimates for the\ne\ufb00ect of Tobin\u2019s q is found to be rather stable over time.\nThe paper relates to three di\ufb00erent strands of the literature. First, the\nerror-in-variables model has been thoroughly studied in econometrics and\nstatistics. Estimation based on third-order moments as the one we employ\ncan be subscribed Geary (1942). Identi\ufb01cation in the error-in-variables model\nis considered by (among others) Reiers\u00f8l (1950); Kapteyn and Wansbeek\n(1983); Bekker (1986). Pal (1980) extends this estimator for the single re-\ngressor case based on higher-order cumulants, while Dagenais and Dagenais\n(1997), Cragg (1997) and Lewbel (1997) consider other functions of mismea-\nsured regressors. An overview of the literature can be found in Wansbeek\nand Meijer (2000) and more recently Schennach (2016).\nA general framework for higher-order moment estimators in models with\n3\nmultiple mismeasured and perfectly measured regressors is proposed in Er-\nickson and Whited (2002). Instead of the moments, it is somewhat simpler to\nrely on higher-order cumulants as in Erickson et al. (2014) as the estimators\nare available in closed-form. Nonparametric identi\ufb01cation and semiparamet-\nric estimation are considered in Schennach and Hu (2013).\nThe second strand of literature concerns divide-and-conquer estimators.\nThese estimators are developed for settings where a massive data set cannot\nbe loaded into memory, see for instance Shi et al. (2018). The idea is to\nconstruct a sequence of estimators on independent subsets of the data, and\nthen aggregate the estimators into a single estimator.\nThis is sometimes\nalso referred to as distributed inference. The common aggregation method\nis to take the mean. Applied to monotone regression, Banerjee et al. (2019)\ndocument a supere\ufb03ciency property of this method. Distributed quantile\nregression is studied by Chen et al. (2019) and Volgushev et al. (2019).\nFinally, rather than taking the mean of the subsample estimators, we rely\non the median. This is shared with median-of-means (MoM) estimators that\nare used to robustify machine learning algorithms in the presence of heavy-\ntailed data. MoM estimators were originally proposed by Nemirovskij and\nYudin (1983), Jerrum et al. (1986), and Alon et al. (1999). In recent years,\nvarious authors show that these estimators attain optimal rates of conver-\ngence under weak assumptions on the data (Hsu and Sabato, 2014, Lugosi\nand Mendelson, 2019, and Lecu\u00b4e and Lerasle, 2020). However, theoretical\nresults are only available under the assumption that the random variables\nhave \ufb01nite second moment. The estimator we propose is closer to a median-\nof-ratios-of-means estimators, which in the worst case scenario does not have\nany \ufb01nite moments.\nThe paper proceeds as follows. In Section 2 we describe the model, the\nproposed estimator and its implementation. In Section 3 we describe asymp-\ntotic results for the divide-and-conquer estimator. The simulation study and\nempirical application are presented in Section 4. Section 5 concludes. Proofs\nare deferred to Appendix A.\n4\n2\nModel, Estimators and Inference\n2.1\nA Simple Error-in-Variables Model\nAs a basis of our analysis we consider the following simpli\ufb01ed error-in-variables\nmodel for one variable\nyi = \u03bei\u03b20 + \u03b5i,\nxi = \u03bei + ui,\n(1)\nfor i = 1, . . . , n. Here the observed variables are (yi, xi), while the remaining\nvariables are latent. The main parameter of interest is \u03b20, the causal e\ufb00ect of\nmarginal change in \u03bei on yi. As \u03bei is not observed, one could naively consider\nestimating \u03b2 by running the OLS regression of yi on xi:\n\u02c6\u03b2OLS =\n1\nn\nPn\ni=1 xiyi\n1\nn\nPn\ni=1 x2\ni\n.\n(2)\nThis estimator, however, generally is inconsistent as in the limit n \u2192\u221e:\n\u02c6\u03b2OLS\np\n\u2212\u2192\u03b20\n\u03c3(2)\n\u03be\n\u03c3(2)\nu + \u03c3(2)\n\u03be\n,\n(3)\nprovided that all stochastic quantities are mutually independent. Here we\ndenote E[\u03be2\ni ] = \u03c32\n\u03be, E[\u03be3\ni ] = \u03c3(3)\n\u03be , E[\u03be4\ni ] = \u03c3(4)\n\u03be\nand similarly for \u03b5i and ui we\nhave E[\u03b52\ni ] = \u03c32\n\u03b5, E[\u03b53\ni ] = \u03c3(3)\n\u03b5 , E[\u03b54\ni ] = \u03c3(4)\n\u03b5 , E[u2\ni ] = \u03c3(2)\nu .\nAs the OLS estimator is generally inconsistent, in what follows we limit\nour attention to a class of method-of-moments estimators that use the infor-\nmation from the higher order moments of the data. The parameter \u03b20 can\nthen be estimated with the estimator attributed to Geary (1942).\nIn what follows, we assume that all random variables are mutually inde-\npendent.\nAssumption 1. (\u03b5i, ui, \u03bei) are mutually independent random variables with\nexpectation zero.\n5\nA direct implication of Assumption 1 is that in population\nE[xiy2\ni ] = \u03c3(3)\n\u03be \u03b22\n0,\nE[x2\ni yi] = \u03c3(3)\n\u03be \u03b20.\n(4)\nThis implies the following moment condition,\nE[gi(\u03b2)] = E[xiy2\ni \u2212x2\ni yi\u03b2] = 0,\n(5)\nfor \u03b2 = \u03b20. Associated with the above population orthogonality conditions\nis the following estimator, attributed to Geary (1942),\n\u02c6\u03b23M =\n1\nn\nPn\ni=1 xiy2\ni\n1\nn\nPn\ni=1 x2\ni yi\n.\n(6)\nAs it is evident from (4), the identifying power of this estimator is sensitive\nto the exact values of \u03b20 and/or \u03c3(3)\n\u03be . In particular, if \u03b20 = 0 and/or \u03c3(3)\n\u03be\n= 0,\nthe probability limit of the estimator is ill-de\ufb01ned.\nThis is also evident from the expression for the asymptotic variance given\nby\nV(\u02c6\u03b23M; \u03b2) =\nE[gi(\u03b20)2]\nE [\u2202gi(\u03b2)/\u2202\u03b2|\u03b2=\u03b20]2 = E[x2\ni y2\ni (yi \u2212xi\u03b20)2]\nE[x2\ni yi]2\n= \u03c3(4)\n\u03be \u03c32\n\u03b5\u03b22\n0 + \u03c32\n\u03be\u03c3(4)\n\u03b5\n+ 2\u03c3(3)\n\u03be \u03c3(3)\n\u03b5 \u03b20 + \u03c32\nu\u03c32\n\u03b5\u03c32\n\u03be\u03b22\n0 + \u03c32\nu\u03c3(4)\n\u03b5\n[\u03c3(3)\n\u03be ]2\u03b22\n0\n.\n(7)\nClearly, when \u03b20 = 0 or \u03c3(3)\n\u03be\n= 0, the variance is ill-de\ufb01ned.\n2.2\nThe Divide-and-Conquer Approach\nIn what follows, we describe the main intuition behind the procedure put\nforward in this paper. Notice that when \u03b20 = 0, the estimator (6) is the\nratio of two correlated sums that both have expectation zero. Borrowing on\nthe idea of the Split Sample IV estimator of Angrist and Krueger (1995), we\ncan easily break the dependence between the limiting value of the numera-\ntor and the denominator by evaluating the denominator and numerator on\n6\nindependent samples. As a result, the resulting estimator will be centered at\nthe true value \u03b20 = 0. However, the estimator will still remain non-normal\nin the limit for \u03b20 = 0, and normal for \u03b20 \u0338= 0, invalidating any standard\ninference approaches.\nThe above problem, however, can be solved. De\ufb01ne two subsets Rj,1 \u2282\n{1, . . . , n} and Rj,2 \u2282{1, . . . , n} such that Rj,1 \u2229Rj,2 = \u2205, denote |Rj,1| =\n|Rj,2| = b/2. The index j will be used to index di\ufb00erent choices of the subsets.\nConsider now the estimator,\n\u02c6\u03b2j,b =\nP\ni\u2208Rj,1 xiy2\ni\nP\ni\u2208Rj,2 x2\ni yi\n.\n(8)\nWhen \u03b20 = 0, (8) is the ratio of two independent sums that both have\nexpectation zero. Intuitively, we would expect that as b \u2192\u221e, \u02c6\u03b2j converges\nweakly to a Cauchy-type random variable with the CDF Fc(x). Let Fj,b(x)\nbe the corresponding CDF of \u02c6\u03b2j,b, then in Appendix A, we show that indeed\nsup\nx\u2208R\n|Fj,b(x) \u2212Fc(x)| \u2264M/\n\u221a\nb,\n(9)\nfor some constant M > 0 when \u03b20 = 0. Note that as Cauchy-type random\nvariables are symmetric, their median is 0, which happens to be exactly the\nvalue \u03b20 = 0 we are after.\nIn cases when the underlying data is a pure cross-section, this facilitates\nthe following strategy to recover the median (thus also \u03b20) of the limiting\nrandom variable with the CDF Fc(x). Randomly partition the n observations\ninto B blocks, so that the number of observations within each block equals\nb = n/B. Within each block, split the sample to form (8), assuming that b/2\nis an integer. This yields a sequence of independent estimators {\u02c6\u03b2DC\nj,b }B\nj=1.\nOur estimator \u02c6\u03b2DC\nb\nfor \u03b2 is the median of this sequence.\nThe algorithm for the Divide-and-conquer estimator is as follows.\nStep 1. Set B such that n/(2B) is an integer.\nStep 2. Partition the data into B adjacent blocks.\n7\nStep 3. Split each block further into two equal sized blocks Rj,1 and\nRj,2.\nStep 4. For j = 1, . . . , B, estimate\n\u02c6\u03b2DC\nj,b =\nP\ni\u2208Rj,1 xiy2\ni\nP\ni\u2208Rj,2 x2\ni yi\n.\n(10)\nStep 5. Estimate \u03b2 by\n\u02c6\u03b2DC\nb\n= median(\u02c6\u03b2DC\n1,b , . . . , \u02c6\u03b2DC\nB,b ).\n(11)\nWe prove below that for any \ufb01xed \u03b20 (including \u03b20 = 0), \u02c6\u03b2DC\nb\nis asymp-\ntotically normal. The convergence rate, however, depends on whether \u03b20 = 0\nor \u03b20 \u0338= 0. In the \ufb01rst case, the convergence rate is B1/2, so it is determined\nonly by the number of blocks B. In the latter case, we end up with the\nstandard (pooled) convergence rate of\n\u221a\nB \u00b7 b = \u221an. Hence, the fact that we\nuse the median to estimate \u03b2 is free of any asymptotic costs, as long as the\nconvergence rate of the estimator is concerned.\n2.3\nSelecting the Number of Blocks\nThe choice of the number of subsample estimators B is important.\nThe\ntheoretical results indicate the B/b should go to zero for consistency of the\nestimator. If B is too large relative to b, \ufb01nite sample bias in the subsample\nestimators does not wash out over the di\ufb00erent blocks. Our simulation results\nshow that we should choose the value of B relatively small. There, we have\na total of 60,000 observations and set B = 20, so that B/b = 0.0066 and\nB = 40 so that B/b = 0.0267. For the latter, we \ufb01nd an increase in bias\nin the coe\ufb03cients and con\ufb01dence intervals that undercover for regressions\nthat include \ufb01xed e\ufb00ects. When we increase the cross-section dimension to\nn = 6, 000 in Tables 4 and 5, so that for B = 40 we get B/b = 0.0133\nand coverage approaches the nominal rate. Optimal selection of the value\nof B is an important topic for further research. We suggest that empirical\n8\nresearchers report their estimates for a range of di\ufb00erent values of B as a\nrobustness check of their results.\n2.4\nInference\nAs the asymptotic variance of the estimator depends on the unknown pa-\nrameter \u03b20, we construct con\ufb01dence intervals from a nonparametric boot-\nstrap procedure.\nFirst, we draw B samples \u02dcej,b with replacement from\n{\u00b1e1,b, . . . , \u00b1eB,b} where ej,b = \u02c6\u03b2DC\nj,b \u2212\u02c6\u03b2DC\nb\n. Note that in view of the asymp-\ntotic distribution, we enforce symmetry by including each ej,b both with a\nplus and a minus sign. We then calculate \u02dc\u03b2DC\ni\n= median(\u02dc\u03b2DC\n1,b , . . . , \u02dc\u03b2DC\nB,b ),\nwhere \u02dc\u03b2DC\nj,b = \u02c6\u03b2DC\nb\n+ \u02dcej,b and i = 1, . . . , Bn. The \u03b1/2 and 1 \u2212\u03b1/2 quantiles\n(qDC\n\u03b1/2, qDC\n1\u2212\u03b1/2) of the empirical distribution of \u02dc\u03b2DC\ni\n\u2212\u02c6\u03b2DC\nb\nare then used to\nconstruct a con\ufb01dence interval as (\u02c6\u03b2DC\nb\n+ qDC\n\u03b1/2, \u02c6\u03b2DC\nb\n+ qDC\n1\u2212\u03b1/2).\n2.5\nExtensions\nTwo extensions to the above methodology are needed to implement the\ndivide-and-conquer estimator in our empirical setting. The \ufb01rst is the addi-\ntion of perfectly measured control variables to the model. The second is to\nconsider a panel data setting.\nFirst, the model (1) can be expanded by including a set of perfectly\nmeasured controls, so that the model is of the form\nyi = \u03bei\u03b20 + z\u2032\ni\u03b3 + \u03b5i.\n(12)\nIn this case, de\ufb01ne\n\u02d9xi = xi \u2212z\u2032\ni\n\uf8eb\n\uf8edX\ni\u2208Rj,1\nziz\u2032\ni\n\uf8f6\n\uf8f8\n\u22121\nX\ni\u2208Rj,1\nzixi,\n(13)\nand similarly for \u02d9yi. Denote by \u00a8xi and \u00a8yi the corresponding estimators on\n9\nthe set Rj,2. We then adapt (10) in the divide-and-conquer algorithm to\n\u02c6\u03b2DC\nj,b =\nP\ni\u2208Rj,1 \u02d9xi \u02d9y2\ni\nP\ni\u2208Rj,2 \u00a8x2\ni \u00a8yi\n.\n(14)\nThis retains the independence between the subsample estimators. Note that\nfor inference on \u03b3 we can adapt the procedure from Section 2.4 and construct\ncon\ufb01dence intervals from the quantiles of \u02dc\u03b3DC\nj,b = (Pn\ni=1 ziz\u2032\ni)\u22121 Pn\ni=1 zi(yi \u2212\nxi \u02dc\u03b2DC\nj,b ).\nAs a second extension, we consider a linear panel data model that will be\nused in our empirical application,\nyit = xit\u03b20 + \u03b1i + \u03bbt + \u03b5it.\n(15)\nIn this case, we construct subsample estimators on cross-sections of the data.\nTo account for individual \ufb01xed e\ufb00ects, we perform a within transformation\non the data. Moreover, to account for time \ufb01xed e\ufb00ects in the model, we\ndemean the data within blocks. Perfectly measured controls are handled in\nthe same way as above.\nThe algorithm for the Panel Divide-and-conquer estimator is as fol-\nlows.\nStep 1. Set B such that N/(2B) is an integer.\nStep 2. If \ufb01xed e\ufb00ects \u03b1i are included in the model, then transform yit\nand xit as\neyit = yit \u2212T \u22121\nT\nX\nt=1\nyit,\nexit = xit \u2212T \u22121\nT\nX\nt=1\nxit.\n(16)\nStep 3. Partition the cross-section at time t into B blocks;\nStep 4. Split each block further into two equal sized blocks Rj,1 and\nRj,2\nStep 5. For j = 1, . . . , B, if time e\ufb00ects \u03bbt are included in the model,\nthen\n10\nFor i \u2208Rj,1,\nbyit = eyit \u2212(2B/N) P\ni\u2208Rj,1 eyit,\nbxit = exit \u2212(2B/N) P\ni\u2208Rj,1 exit.\nFor i \u2208Rj,2,\nbyit = eyit \u2212(2B/N) P\ni\u2208Rj,2 eyit,\nbxit = exit \u2212(2B/N) P\ni\u2208Rj,2 exit.\nOtherwise set byit = eyit and bxit = exit.\nStep 6. Estimate\n\u02c6\u03b2DC\njt,b =\nP\ni\u2208Rj,1 bxitby2\nit\nP\ni\u2208Rj,2 bx2\nitbyit\n.\n(17)\nStep 7. Estimate \u03b2 by\n\u02c6\u03b2DC\nb\n= median(\u02c6\u03b2DC\n11,b, . . . , \u02c6\u03b2DC\nBT,b).\n(18)\n3\nTheoretical Results\nWe start by making the following assumption on the moments of (\u03bei, ui, \u03b5i)\nthat facilitate a Berry-Esseen inequality in the proof of the main theorem.\nWe limit our attention to the basic estimator we suggest in Section 2.2. In\nthe following, denote by \u03a6(x) and \u03c6(x) the CDF/PDF of a standard normal\nr.v. and by Fc(x)/fc(x) the CDF/PDF of a Cauchy r.v.\nAssumption 2. E[|\u03bei|6] < \u221e, E[|ui|6] < \u221e, E[|\u03b5i|6] < \u221e.\nWe impose the following assumption on the number of blocks B, which\nis chosen as a function of the sample size within each block b.\nAssumption 3. B(b)/b \u21920.\nNote that when \u03b20 = 0, the estimator can be decomposed as\n\u02c6\u03b2j,b =\nP\ni\u2208Rj,1 xi\u03b52\ni\nP\ni\u2208Rj,2 x2\ni \u03b5i\n= vj,b\nwj,b\n,\n(19)\nwhere |Rj,1| = |Rj,2| = b/2 and j = 1, . . . , B.\nDenote \u03c32\nv = E[v2\nj,b] and\n\u03c32\nw = E[w2\nj,b]. When \u03b20 \u0338= 0, de\ufb01ne wi = xi\u03b52\ni + 2\u03b20(\u03be2\ni + \u03beiui)\u03b5i and \u03c32\n\u03b2 =\n(\u03b20\u03c3(3)\n\u03be )\u22122E [w2\ni ].\nThis brings us to our main result.\n11\nTheorem 1. Suppose Assumptions 1 to 3 hold. Let\n\u02c6\u03b2DC\nb\n= median({\u02c6\u03b2j,b}B\nj=1).\n(a) When \u03b20 = 0,\n\u221a\nB\n\u0012\u03c3w\n\u03c3v\n\u02c6\u03b2DC\nb\n\u0013\n\u2212\u2192d N\n\u0012\n0,\n1\n4fc(0)2\n\u0013\n.\n(20)\n(b) When \u03b20 \u0338= 0,\n\u221an\n \u02c6\u03b2DC\nb\n\u2212\u03b20\n\u03c3\u03b2\n!\n\u2212\u2192d N\n\u0012\n0,\n1\n4\u03c6(0)2\n\u0013\n.\n(21)\nWe see that regardless of the value of \u03b20, the estimator is asymptotically\nnormal. The asymptotic distribution, on the other hand, is generally discon-\ntinuous at \u03b20. In particular, for \u03b20 = 0, the convergence rate is\n\u221a\nB. Since\nAssumption 3 requires that B/b = B2/n \u21920, the maximal convergence rate\nis below n1/4. When \u03b20 \u0338= 0, we recover the standard \u221an convergence rate.\nWe also see that the asymptotic variance depends on the, evidently un-\nknown, value of \u03b20.\nInference therefore proceeds via the non-parametric\nbootstrap discussed in the previous section that accommodates cases (a) and\n(b) simultaneously.\n4\nNumerical Results\n4.1\nMonte Carlo Study\nIn this section we consider the simulation set-up from Erickson et al. (2014).\nTheir setup is calibrated in order to re\ufb02ect several characteristics of the data\nused in their analysis. In particular, we consider a simple linear panel data\nmodel of the form,\nyit = zit\u03b3 + \u03beit\u03b2 + uit,\nxit = \u03beit + eit.\n(22)\n12\nHere i = 1, . . . , n with n = 3, 000 and t = 1, . . . , T with T = 20.\nThe\nerrors uit and eit are i.i.d. Gamma random variables standardized using the\npopulation mean and standard deviation. The scale parameter is set to 1\nand the shape parameter is set to 0.32 for uit and 0.09 for eit.\nThe perfectly measured controls and the mismeasured regressor are gen-\nerated using an autoregressive processes of order 1 - AR(1), as follows\n\u03beit = \u03b4\u03be + \u03c6\u03be\u03bei,t\u22121 + v\u03be\nit,\nzit = \u03b4z + \u03c6zzi,t\u22121 + vz\nit.\n(23)\nHere we set \u03c6\u03be = 0.78 and \u03c6z = 0.48. The intercepts are set to match the \ufb01rst\nmoment of Tobin\u2019s q and cash \ufb02ow in the data as \u03b4\u03be = 0.570 and \u03b4z = 0.094.\nThe errors (v\u03be\nit, vz\nit) are again independent Gamma random variables. The\nscale parameter is set to 1, the shape parameter for v\u03be\nit equal to 0.007 and\nfor vz\nit equal to 2.08. We follow the standard practise in the literature and\ninitialize the processes for \u03beit and zit in the recent past by setting \u03bei,\u221210 =\nzi,\u221210 = 0 for all i. We then generate T +10 time series observations for both\nprocesses and drop the \ufb01rst 10 periods.\nAfter having generated zit and \u03beit, we transform these to ensure that the\ncovariance matrix calculated using all available data is equal to the covariance\nmatrix of xit and zit in the data, with the variance of Tobin\u2019s q multiplied by\n\u03c4 2 = 0.45 and the covariances multiplied by\n\u221a\n\u03c4 2. Numerically, the covariance\nmatrix is\nC =\n \n16.130\n0.489\n0.258\n!\n.\n(24)\nFinally, we generate the observed variables as follows\nxit = \u03beit +\nq\n\u03c4 \u22122(1 \u2212\u03c4 2)C1,1eit\nyit = \u00b5y + \u03beit\u03b2 + zit\u03b3 +\nq\n\u03c32\ny \u2212var(\u03beit\u03b2 + zit\u03b3)uit.\n(25)\nHere \u00b5y and \u03c32\ny are set to match the population mean and variance of\nthe investment variable in the data. We consider two choices for \u03b2. In the\n\ufb01rst \u03b2 = 0.025 as in Erickson et al. (2014), while in the second \u03b2 = 0. The\n13\ncoe\ufb03cient for control variable zit is \ufb01xed to \u03b3 = 0.05.\nWe estimate the parameters in (25) using OLS (OLS), the third-order\nmoment estimator (3M) and the divide-and-conquer estimator (DC). For the\ndivide-and-conquer estimator, we vary the number of blocks per time period\nfrom 1 to 2, so we take the median over B \u00b7T = 20 and B \u00b7T = 40 subsample\nestimators. In each time period, the partition of the \ufb01rms is random.\nBootstrap con\ufb01dence intervals are constructed as outlined in Section 2.4\nwith Bn = 399. For the third-order moment estimator, con\ufb01dence intervals\nare calculated as in Erickson and Whited (2002).\n[Table 1 near here.]\nTable 1 shows the mean and standard deviations of the estimates for the\nq-coe\ufb03cient \u03b2 and the cash \ufb02ow coe\ufb03cient \u03b1. When \u03b20 = 0.025, we see that\nthe OLS estimates for \u03b2 and \u03b1 are badly biased due to the measurement error\nin the process. The third-order moment estimators as well as the divide-and-\nconquer methods show no to very little bias. The standard errors of the\ndivide-and-conquer estimators are larger relative to the third-order moment\nestimator.\nWhen \u03b20 = 0, we see that the third-order moment estimator is badly\nde\ufb01ned, with the standard error going up substantially.\nThe divide-and-\nconquer estimators on the other hand perform well, with standard deviations\nnearly identical to those when \u03b20 = 0.025.\n[Table 2 near here.]\nTable 2 shows the coverage rates for the various methods. As expected,\nthe bias in the OLS estimator when \u03b20 \u0338= 0 results in con\ufb01dence intervals that\ndo not include the true parameter. The con\ufb01dence intervals corresponding\nto the 3M estimator are somewhat conservative, especially when we include\n\ufb01xed e\ufb00ects. For the DC estimator, we \ufb01nd overall close to nominal coverage\nexcept when \u03b20 = 0.025 and we include \ufb01xed e\ufb00ects. Table 5 shows that\nincreasing the sample size to n = 6, 000 largely resolves this issue.\n14\n4.2\nEmpirical Results\nWe consider an application from the corporate \ufb01nance literature that seeks\nto determine the relation between actual investment and unobserved invest-\nment opportunities in capital as in Fazzari et al. (1988). The investment\nopportunities are proxied by Tobin\u2019s q, which contains considerable mea-\nsurement error. The third-order moment estimator (6) and generalizations\nthereof have been applied to account for this measurement error in Erickson\nand Whited (2000), Erickson and Whited (2012) and Erickson et al. (2014).\nWhile identi\ufb01cation problems due to lack of skewness were investigated in\nErickson and Whited (2012), problems that arise because \u03b20 is (close to)\nzero, have not been addressed.\nWe use the data of Erickson et al. (2014) to estimate the linear panel\ndata model\nyit = z\u2032\nit\u03b3 + xit\u03b2 + \u03b5it,\n(26)\nwhere i = 1, . . . , n indexes the \ufb01rm, and t = 1, . . . , T the year. The data\nranges from 1970 to 2011. After removing \ufb01rms for which only one year is\navailable, the sample consists of 121,733 \ufb01rm-year observations. The outcome\nvariable yit is investment as constructed by Erickson et al. (2014).\nThe\nperfectly measured control variables zit include an intercept and a measure\nof cash \ufb02ow, xit denotes Tobin\u2019s q.\nWe estimate the e\ufb00ect of Tobin\u2019s q on investment in (26) by (1) OLS, (2)\nthe third-order moment estimator (6) and (3) the divide-and-conquer algo-\nrithm. We calculate con\ufb01dence intervals for (6) as described in Erickson and\nWhited (2002). For the divide-and-conquer method, we apply the bootstrap\nprocedure from Section 2.4.\nFor the divide-and-conquer estimator, for every year we divide the data\ninto 2 blocks, which for the full sample corresponds to 80 blocks. We also\nreport results for 1 block per year. Since for each block we split the data\ninto two halves to calculate the numerator and denominator of the subsample\nestimators, in each year we discard a randomly selected subset of \ufb01rms so\nthat the number of \ufb01rms is a multiple of 2 (for DC with 1 block per year) or\na multiple of 4 (for DC with 2 blocks per year).\n15\n[Table 3 near here.]\nWe \ufb01rst report the full sample pooled estimators and standard errors in\nTable 3. For the OLS estimators, we see the signi\ufb01cant e\ufb00ect of cash \ufb02ow\non investment.\nThis questions q-theory, which states that in a regression\nof investment on q, control variables must be insigni\ufb01cant. Indeed, we see\nthat this theory can be aligned with empirical evidences by the third-order\nmoment estimators. These conclusions are upheld by the divide-and-conquer\nmethods: Tobin\u2019s q has a signi\ufb01cant positive e\ufb00ect on investment, while\ncash \ufb02ow does not. The exception is formed by the results from divide-and-\nconquer with both \ufb01rm and year e\ufb00ects. In this case, the con\ufb01dence intervals\nfor the Tobin\u2019s q include zero.\nSecondly, Erickson et al. (2014) document that the coe\ufb03cient estimates\nmay be varying over time. We therefore apply the same estimation method\non subsamples of the data. The \ufb01rst subsample is 1970-1980, which we then\nexpand by one year at a time until we reach the full-sample estimates in\n2011. For this exercise, we limit our attention to the model with \ufb01rm \ufb01xed\ne\ufb00ects. We report results for the divide-and-conquer estimator with 2 blocks\nper year. Results for 1 block per year are reported in Figures 3 and 4.\n[Figure 1 near here.]\nFigure 1 shows the estimates for Tobin\u2019s q alongside the 95% con\ufb01dence\nintervals. Interestingly, in the \ufb01rst half of the time period, we \ufb01nd that both\nthe third-order moment estimator and the DC estimator include zero in the\ncon\ufb01dence interval. This is paired with the observation that the third-order\nmoment estimator takes a value for Tobin\u2019s q which is an order of magnitude\nlarger than the full-sample estimator.\n[Figure 2 near here.]\nFigure 2 shows the estimated cash \ufb02ow coe\ufb03cient. While the con\ufb01dence\nintervals for the third-order moment estimator include zero for all time peri-\nods, the divide-and-conquer estimator shows some mild evidence for a cash\n\ufb02ow e\ufb00ect, especially in the early years of the sample. This aligns with the\n16\n\ufb01ndings by Andrei et al. (2019) who \ufb01nd that q-theory has become increas-\ningly e\ufb03cient in explaining investment patterns.\n5\nConcluding Remarks\nEstimators based on higher-order moments of the data can eliminate the\ne\ufb00ect of measurement error.\nHowever, if the coe\ufb03cient \u03b20 of the latent\nregressor is zero, the estimators converge weakly to a ratio of correlated mean\nzero normal random variable. As a result, standard inference procedures are\nnot applicable in this case.\nAs a solution to this problem we suggest the divide-and-conquer estima-\ntor that estimates the parameter of interest using the median of subsample\nestimators. We show this estimator is consistent and suggest a bootstrap\nbased inference procedure that is applicable irrespective of the coe\ufb03cient \u03b20.\nThe estimator and inference procedure are intuitive and easy to implement\nby practitioners. Monte Carlo results indicate that this bootstrap procedure\nwell approximates the \ufb01nite sample distribution of the estimator.\nFinally, we analyse the data on \ufb01rm investment, Tobin\u2019s q and cash \ufb02ow\nfrom Erickson et al. (2014) and do not \ufb01nd signi\ufb01cant evidence for the ef-\nfect of cash \ufb02ow in \ufb01rm investment. Interestingly enough, we \ufb01nd substantial\nchanges in the estimated relation between investment, Tobin\u2019s q and cash \ufb02ow\nover time. In particular, we \ufb01nd rather extreme point estimates and con\ufb01-\ndence intervals in time periods before the mid-1980s for the third-moment\nestimator of Erickson et al. (2014). These occur precisely in time periods\nin which the divide-and-conquer estimator is not signi\ufb01cantly di\ufb00erent from\nzero. On the other hand, the divide-and-conquer estimates for the e\ufb00ect of\nTobin\u2019s q is found to be rather stable over time. These observations con\ufb01rm\nthe empirical relevance of our proposed statistical procedure.\nAcknowledgements\nWe thank Gerard van den Berg, Simon Broda, Noud\nvan Giersbergen, Toru Kitagawa, Frank Kleibergen, Ruud Koning, Tom\nWansbeek, and seminar participants at the Tinbergen Institute Amsterdam\nand the University of Groningen, for helpful comments.\nWe thank Toni\n17\nWhited for sharing the data. Financial support from the Netherlands Organi-\nzation for Scienti\ufb01c Research (NWO) under research grant number 201E.011\n(TB) and 451 \u221217 \u2212002 (AJ) is gratefully acknowledged.\nDisclosure statement\nThe authors report there are no competing inter-\nests to declare.\nData availability statement\nThe authors con\ufb01rm that the code and data\nsupporting the \ufb01ndings of this study are available within the supplementary\nmaterials.\nReferences\nAlon, N., Matias, Y., and Szegedy, M. (1999).\nThe space complexity of\napproximating the frequency moments. Journal of Computer and System\nSciences, 58(1):137\u2013147.\nAndrei, D., Mann, W., and Moyen, N. (2019). Why did the q theory of\ninvestment start working?\nJournal of Financial Economics, 133(2):251\u2013\n272.\nAngrist, J. D. and Krueger, A. B. (1995). Split-sample instrumental variables\nestimates of the return to schooling. Journal of Business and Economic\nStatistics, 13(2):225\u2013235.\nBanerjee, M., Durot, C., and Sen, B. (2019). Divide and conquer in nonstan-\ndard problems and the super-e\ufb03ciency phenomenon. Annals of Statistics,\n47(2):720\u2013757.\nBekker, P. A. (1986).\nComment on identi\ufb01cation in the linear errors in\nvariables model. Econometrica, 54(1):215\u2013217.\nBlundell, R., Bond, S., Devereux, M., and Schiantarelli, F. (1992). Invest-\nment and Tobin\u2019s q: Evidence from company panel data. Journal of Econo-\nmetrics, 51(1-2):233\u2013257.\nChen, X., Liu, W., and Zhang, Y. (2019). Quantile regression under memory\nconstraint. Annals of Statistics, 47(6):3244\u20133273.\n18\nCragg, J. G. (1997). Using higher moments to estimate the simple errors-in-\nvariables model. RAND Journal of Economics, 28(0):S71\u2013S91.\nDagenais, M. G. and Dagenais, D. L. (1997). Higher moment estimators for\nlinear regression models with errors in the variables. Journal of Econo-\nmetrics, 76(1-2):193\u2013221.\nErickson, T., Jiang, C. H., and Whited, T. M. (2014). Minimum distance es-\ntimation of the errors-in-variables model using linear cumulant equations.\nJournal of Econometrics, 183(2):211\u2013221.\nErickson, T. and Whited, T. M. (2000). Measurement error and the relation-\nship between investment and q. Journal of Political Economy, 108(5):1027\u2013\n1057.\nErickson, T. and Whited, T. M. (2002). Two-step GMM estimation of the\nerrors-in-variables model using high-order moments. Econometric Theory,\n18(3):776\u2013799.\nErickson, T. and Whited, T. M. (2012).\nTreating measurement error in\nTobin\u2019s q. Review of Financial Studies, 25(4):1286\u20131329.\nFazzari, S. M., Hubbard, R. G., Petersen, B. C., et al. (1988). Financing\nconstraints and corporate investment. Brookings Papers on Economic Ac-\ntivity, 19(1):141\u2013206.\nGeary, R. C. (1942). Inherent relations between random variables. In Proceed-\nings of the Royal Irish Academy. Section A: Mathematical and Physical\nSciences, volume 47, pages 63\u201376.\nHsu, D. and Sabato, S. (2014). Heavy-tailed regression with a generalized\nmedian-of-means. In Proceedings of the 31st International Conference on\nMachine Learning, volume 32, pages 37\u201345.\nJerrum, M. R., Valiant, L. G., and Vazirani, V. V. (1986). Random gener-\nation of combinatorial structures from a uniform distribution. Theoretical\nComputer Science, 43:169\u2013188.\nKapteyn, A. and Wansbeek, T. (1983). Identi\ufb01cation in the linear errors in\nvariables model. Econometrica, 51(6):1847\u20131849.\nLecu\u00b4e, G. and Lerasle, M. (2020). Robust machine learning by median-of-\nmeans: theory and practice. Annals of Statistics, 48(2):906\u2013931.\nLewbel, A. (1997). Constructing instruments for regressions with measure-\n19\nment error when no additional data are available, with an application to\npatents and randd. Econometrica, 65(5):1201\u20131213.\nLugosi, G. and Mendelson, S. (2019). Risk minimization by median-of-means\ntournaments. Journal of the European Mathematical Society, 22(3):925\u2013\n965.\nNemirovskij, A. S. and Yudin, D. B. (1983). Problem complexity and method\ne\ufb03ciency in optimization. New York: Wiley-Interscience.\nPal, M. (1980). Consistent moment estimators of regression coe\ufb03cients in the\npresence of errors in variables. Journal of Econometrics, 14(3):349\u2013364.\nReiers\u00f8l, O. (1950). Identi\ufb01ability of a linear relation between variables which\nare subject to error. Econometrica, 18(4):375\u2013389.\nRiddick, L. A. and Whited, T. M. (2009). The corporate propensity to save.\nJournal of Finance, 64(4):1729\u20131766.\nSchennach, S. M. (2016). Recent advances in the measurement error litera-\nture. Annual Review of Economics, 8:341\u2013377.\nSchennach, S. M. and Hu, Y. (2013).\nNonparametric identi\ufb01cation and\nsemiparametric estimation of classical measurement error models with-\nout side information.\nJournal of the American Statistical Association,\n108(501):177\u2013186.\nShi, C., Lu, W., and Song, R. (2018). A massive data framework for m-\nestimators with cubic-rate. Journal of the American Statistical Associa-\ntion, 113(524):1698\u20131709.\nVolgushev, S., Chao, S.-K., and Cheng, G. (2019). Distributed inference for\nquantile regression processes. Annals of Statistics, 47(3):1634\u20131662.\nWansbeek, T. J. and Meijer, E. (2000). Measurement error and latent vari-\nables in econometrics, volume 37. Amsterdam: Elsevier.\n20\nAppendix A\nProofs\nA.1\nThe Case when \u03b20 = 0\nDenote the subsample estimator\n\u02c6\u03b2DC\nj,b =\nP\ni\u2208Rj,1 xi\u03b52\ni\nP\ni\u2208Rj,2 x2\ni \u03b5i\n= vj,b\nwj,b\n,\n(A.1)\nwhere |Rj,1| = |Rj,2| = b/2 and j = 1, . . . , B. Let \u03c32\nv = E[v2\nj,b] and \u03c32\nw =\nE[w2\nj,b] and denote \u03b7 = \u03c3w/\u03c3v. Denote \u02c6F(x) =\n1\nB\nPB\nj=1 1[\u03b7 \u00b7 \u02c6\u03b2DC\nj,b\n\u2264x] and\nF(x) = P\n\u0010\n\u03b7 \u00b7 \u02c6\u03b2DC\nj,b \u2264x\n\u0011\n. Denote by Fc(x) and fc(x) the CDF and PDF of a\nCauchy random variable.\nA.1.1\nSubsample Estimator Distribution\nLemma 1. If \u03b20 = 0, we have that\nsup\nx\u2208R\n|F(x) \u2212Fc(x)| = O(b\u22121/2).\n(A.2)\nProof : We have that\nF(x) = P\n\u0010\n\u03b7 \u00b7 \u02c6\u03b2DC\nj,b \u2264x\n\u0011\n= P (vj,b/\u03c3v \u2264x \u00b7 wj,b/\u03c3w, wj,b > 0)\n+ P (vj,b/\u03c3v \u2265x \u00b7 wj,b/\u03c3w, wj,b < 0) .\n(A.3)\nFor k = 1, 2, de\ufb01ne Vj,b = b\u22121/2vj,b/\u03c3v and Wj,b = b\u22121/2wj,b/\u03c3w Under As-\nsumption 2, by a standard Berry-Esseen bound, supx\u2208R |P(Vj,b \u2264x) \u2212\u03a6(x)| =\nO(b\u22121/2) and supx\u2208R |P(Wj,b \u2264x) \u2212\u03a6(x)| = O(b\u22121/2). Then also,\nF(x) =\nZ \u221e\n0\nfWj,b(y)\nZ xy\n\u2212\u221e\nfVj,b(z)dzdy +\nZ 0\n\u2212\u221e\nfWj,b(y)\nZ \u221e\nxy\nfVj,b(z)dzdy\n=\nZ \u221e\n0\n\u03c6(y)\u03a6(xy)dy +\nZ 0\n\u2212\u221e\n\u03c6(y)(1 \u2212\u03a6(xy))dy + O(b\u22121/2),\n(A.4)\nand the result holds uniformly over x. Here, for simplicity, we assume that the\n21\nunderlying variables Vj,b hand Wj,b have a continuous distribution. We make\nthis assumption only for the sake of exposition as the main result evidently\nfollows even without the continuity.\nNote that for any two independent standard normal random variables,\nlikewise\nP (Z1/Z2 \u2264x) =\nZ \u221e\n0\n\u03c6(y)\u03a6(xy)dy +\nZ 0\n\u2212\u221e\n\u03c6(y)(1 \u2212\u03a6(xy))dy.\n(A.5)\nand the result follows.\n\u25a0\nA.1.2\nProof for Theorem 1 - Part (a)\nSuppose for simplicity that B is odd. Denote by TB = PB\nj=1 I[\u03b7 \u00b7 \u02c6\u03b2DC\nj,b\n>\nt/\n\u221a\nB]. Since \u02c6\u03b2DC\nb\n= median(\u02c6\u03b2DC\n1,b , . . . , \u02c6\u03b2DC\nB,b ), we have that\nP(\u03b7 \u00b7 \u02c6\u03b2DC\nb\n\u2264t/\n\u221a\nB) = P(TB \u2264(B \u22121)/2).\n(A.6)\nBecause the estimators \u02c6\u03b2DC\nj,b are calculated on independent samples, we have\nthat TB \u223cBin(B, pB(t)) with pB(t) = 1 \u2212F(t/\n\u221a\nB) = 1 \u2212Fc(t/\n\u221a\nB) +\nO(1/\n\u221a\nb) by Lemma 1. Now, the r.h.s. of (A.6) equals\nP\n \nTB \u2212BpB(t)\np\nBpB(t)(1 \u2212pB(t))\n\u2264(B \u22121)/2 \u2212BpB(t)\np\nBpB(t)(1 \u2212pB(t))\n!\n= P\n\uf8eb\n\uf8ed\nB(b)\nX\nj=1\nYj,b \u2264xB(t)\n\uf8f6\n\uf8f8.\n(A.7)\n22\nWe have that\nxB(t) = (B \u22121)/2 \u2212BpB(t)\np\nBpB(t)(1 \u2212pB(t))\n=\n\u221a\nB(1 \u2212pB(t) \u22121/2) + O(1/\n\u221a\nB)\np\npB(t)(1 \u2212pB(t))\n=\n\u221a\nB\n\u0010\nFc(t/\n\u221a\nB) \u2212Fc(0)\n\u0011\n+ O(\np\nB/b) + O(1/\n\u221a\nB)\nq\n(1 \u2212Fc(t/\n\u221a\nB))Fc(t/\n\u221a\nB) + O(1/\n\u221a\nb)\n= t\nFc(t/\n\u221a\nB) \u2212Fc(0)\n(t/\n\u221a\nB)\nq\n1/4 + O(1/\n\u221a\nB) + O(1/\n\u221a\nb)\n+ o(1)\n= 2fc(0)t + o(1).\n(A.8)\nWe apply a standard CLT for triangular arrays to PB(b)\nj=1 Yj,b to \ufb01nd that\n2\u03b7fc(0) \u00b7\n\u221a\nB(\u02c6\u03b2DC\nb\n\u22120) \u2212\u2192d N(0, 1).\n(A.9)\nA.2\nThe Case when \u03b20 \u0338= 0\nWe \ufb01rst de\ufb01ne the following: \u02c6F(x) =\n1\nB\nPB\nj=1 1[\n\u221a\nb(\u02c6\u03b2DC\nj,b \u2212\u03b20)/\u03c3\u03b2 \u2264x] and\nF(x) = P\n\u0010\u221a\nb(\u02c6\u03b2DC\nj,b \u2212\u03b20)/\u03c3\u03b2 \u2264x\n\u0011\n. We write out \u02c6\u03b2DC\nj,b as\n\u02c6\u03b2DC\nj,b =\nP\ni\u2208Rj,1 (\u03be3\ni \u03b22\n0 + xi\u03b52\ni + 2\u03b20(\u03be2\ni + \u03beiui)\u03b5i)\nP\ni\u2208Rj,2 (\u03be3\ni \u03b20 + x2\ni \u03b5i + \u03b20(u2\ni + 2ui\u03bei)\u03bei)\n= \u03b2 +\n1\nb\nP\ni\u2208Rj,1 (xi\u03b52\ni + 2\u03b20(\u03be2\ni + \u03beiui)\u03b5i)\n\u03b2\u03c3(3)\n\u03be\n+ Op(b\u22121).\n(A.10)\nDe\ufb01ne wi = xi\u03b52\ni + 2\u03b20(\u03be2\ni + \u03beiui)\u03b5i and \u03c32\n\u03b2 = (\u03b20\u03c3(3)\n\u03be )\u22122E [w2\ni ], then\nP\n \n\u221a\nb(\u02c6\u03b2DC\nj,b \u2212\u03b20)\n\u03c3\u03b2\n\u2264x\n!\n= P\n 1\n\u221a\nb\nP\ni\u2208Rj,1 wi\nE[w2\ni ]1/2\n\u2264x\n!\n+ O(b\u22121).\n(A.11)\n23\nUsing again a Berry-Esseen bound facilitated by Assumption 2, we get\nsup\nx\u2208R\n|F(x) \u2212\u03a6(x)| = O(1/\n\u221a\nb).\n(A.12)\nA.2.1\nProof for Theorem 1 - Part (b)\nThe proof is similar to that of Theorem 1. Suppose again that B is odd.\nDenote by TB = PB\nj=1 I[\n\u221a\nb(\u02c6\u03b2DC\nj,b \u2212\u03b2)/\u03c3\u03b2 > t/\n\u221a\nB], then\nP\n\u0010\u221a\nb(\u02c6\u03b2DC \u2212\u03b2)/\u03c3\u03b2 \u2264t/\n\u221a\nB\n\u0011\n= P(TB \u2264(B \u22121)/2).\n(A.13)\nNow TB \u223cBin(B, pB) with pB = 1 \u2212F(t/\n\u221a\nB) = 1 \u2212\u03a6(t/\n\u221a\nB) + O(1/\n\u221a\nb).\nProceeding as in the proof for Theorem 1, the r.h.s. of (A.13) equals\nP\n \nTB \u2212BpB\np\nBpB(1 \u2212pB)\n\u2264(B \u22121)/2 \u2212BpB\np\nBpB(1 \u2212pB)\n!\n= P\n\uf8eb\n\uf8ed\nB(b)\nX\ni=1\nYi,b \u2264xB\n\uf8f6\n\uf8f8.\n(A.14)\nHere\nxB = (B \u22121)/2 \u2212BpB\np\nBpB(1 \u2212pB)\n=\n\u221a\nB(1 \u2212pB \u22121/2) + O(1/\n\u221a\nB)\np\npB(1 \u2212pB)\n=\n\u221a\nB\n\u0010\n\u03a6(t/\n\u221a\nB) \u2212\u03a6(0)\n\u0011\n+ O(\np\nB/b) + O(1/\n\u221a\nB)\nq\n(1 \u2212\u03a6(t/\n\u221a\nB))\u03a6(t/\n\u221a\nB) + O(1/\n\u221a\nb)\n= t\n\u03a6(t/\n\u221a\nB) \u2212\u03a6(0)\n(t/\n\u221a\nB)\nq\n1/4 + O(1/\n\u221a\nB) + O(1/\n\u221a\nb)\n+ o(1)\n= 2t\u03c6(0) + o(1).\n(A.15)\nWe now \ufb01nd that\n2\u03c3\u03b2\u03c6(0) \u00b7\n\u221a\nB \u00b7 b(\u02c6\u03b2DC \u2212\u03b20) \u2212\u2192d N(0, 1).\n(A.16)\n24\n[Table 4 near here.]\n[Table 5 near here.]\n[Figure 3 near here.]\n[Figure 4 near here.]\n25\nTable 1\nSimulation: bias and standard deviation.\n\u03b20 = 0, \u03b10 = 0.05\n(1)\n(2)\n(3)\n(4)\nOLS\nb\u03b2\n0.000\n(0.000)\n0.000 (0.000) 0.000 (0.000) 0.000 (0.000)\nb\u03b1\n0.050\n(0.002)\n0.050 (0.002) 0.050 (0.002) 0.050 (0.002)\n3M\nb\u03b2\n0.036\n(7.513)\n0.039 (2.774) 0.007 (1.418) 0.031 (4.966)\nb\u03b1 -0.017 (14.081) -0.012 (4.483) 0.038 (2.717) 0.004\n(7.43)\nDC(20)\nb\u03b2\n0.001\n(0.008)\n0.001 (0.008) 0.001 (0.007) 0.001 (0.008)\nb\u03b1\n0.048\n(0.015)\n0.049 (0.013) 0.048 (0.014) 0.049 (0.013)\nDC(40)\nb\u03b2\n0.001\n(0.005)\n0.001 (0.005) 0.001 (0.005) 0.001 (0.005)\nb\u03b1\n0.047\n(0.010)\n0.048 (0.009) 0.047 (0.010) 0.048 (0.008)\n\u03b20 = 0.025, \u03b10 = 0.05\n(1)\n(2)\n(3)\n(4)\nOLS\nb\u03b2\n0.011\n(0.000)\n0.009 (0.000) 0.011 (0.000) 0.009 (0.000)\nb\u03b1\n0.077\n(0.001)\n0.075 (0.001) 0.077 (0.001) 0.075 (0.001)\n3M\nb\u03b2\n0.025\n(0.000)\n0.025 (0.001) 0.025 (0.000) 0.025 (0.001)\nb\u03b1\n0.050\n(0.002)\n0.050 (0.002) 0.050 (0.002) 0.050 (0.002)\nDC(20)\nb\u03b2\n0.026\n(0.007)\n0.024\n(0.01) 0.026 (0.007) 0.025\n(0.01)\nb\u03b1\n0.048\n(0.014)\n0.051 (0.015) 0.048 (0.014) 0.050 (0.015)\nDC(40)\nb\u03b2\n0.026\n(0.007)\n0.018 (0.007) 0.026 (0.007) 0.019 (0.008)\nb\u03b1\n0.049\n(0.013)\n0.061 (0.011) 0.049 (0.013) 0.059 (0.012)\nFE\nNo\nYes\nNo\nYes\nTE\nNo\nNo\nYes\nYes\nNote: mean and standard deviation of the estimates for \u03b2 and \u03b1 over 20, 000\ndraws of the error-in-variables model yit = \u03beit\u03b2 + zit\u03b1 + ui, xit = \u03beit + vit\nwith n = 3, 000 and T = 20. Estimation by least squares (OLS), the third-\norder moment estimator by Geary (1942) (3M), and the divide-and-conquer\nestimator with B blocks (DCB). The standard deviation of the estimates is\nlisted in brackets. Model (1) includes an intercept, model (2) \ufb01xed e\ufb00ects,\nmodel (3) time e\ufb00ects, and model (4) two-way \ufb01xed e\ufb00ects. For DC, in the\npresence of \ufb01xed e\ufb00ects, we do a within transformation on the complete\ndata set. For time e\ufb00ects, we demean within blocks.\n26\nTable 2\nSimulation: coverage.\n\u03b20 = 0, \u03b10 = 0.05\n\u03b20 = 0.025, \u03b10 = 0.05\nOLS\n\u03b2\n95.2\n94.5\n95.1\n94.5\n0.0\n0.0\n0.0\n0.0\n\u03b1\n95.1\n94.4\n95.1\n94.3\n0.0\n0.0\n0.0\n0.0\n3M\n\u03b2\n96.6\n98.2\n96.6\n98.2\n94.7\n95.5\n94.8\n95.5\n\u03b1\n96.5\n98.3\n96.5\n98.2\n95.0\n94.7\n95.0\n94.7\nDC(20)\n\u03b2\n96.6\n97.0\n96.7\n96.9\n94.1\n92.3\n93.9\n92.7\n\u03b1\n96.7\n96.7\n96.5\n96.7\n93.9\n92.2\n93.7\n92.7\nDC(40)\n\u03b2\n95.7\n96.3\n95.5\n96.3\n94.3\n75.5\n94.2\n79.8\n\u03b1\n95.4\n96.1\n95.4\n95.9\n94.0\n75.3\n94.1\n79.8\nFE\nNo\nYes\nNo\nYes\nNo\nYes\nNo\nYes\nTE\nNo\nNo\nYes\nYes\nNo\nNo\nYes\nYes\nNote: reported is the coverage rate (\u00d7100) for the model and methods\nas describe below Table 1. Nominal coverage rate is 0.95. Con\ufb01dence\nintervals for the 3M estimator are calculated as in Erickson and Whited\n(2002). Con\ufb01dence intervals for the DC estimator are obtained by a\nbootstrap procedure. To obtain a bootstrap draw, we draw samples\ne\u2217\ni,b with i = 1, . . . , B with replacement from {\u00b1e1,b, . . . , \u00b1eB,b} where\nei,b = \u02c6\u03b2i,b\u2212\u02c6\u03b2DC\nb\nand calculate the median of {e\u2217\n1,b+ \u02c6\u03b2DC\nb\n, . . . , e\u2217\nB,b+ \u02c6\u03b2DC\nb\n}.\nWe repeat this procedure 399 times and form a con\ufb01dence interval by\ntaking the 5 and 95 percentiles.\n27\nTable 3\nApplication: full sample estimates.\n(1)\n(2)\n(3)\n(4)\nOLS\n0.008\n0.009\n0.009\n0.009\n(0.008, 0.008)\n(0.009, 0.009)\n(0.009, 0.009)\n(0.008, 0.009)\n3M\n0.024\n0.041\n0.024\n0.037\n(0.022, 0.025)\n(0.034, 0.048)\n(0.023, 0.026)\n(0.031, 0.042)\nDC(2)\n0.023\n0.031\n0.035\n0.020\n(0.013, 0.034)\n(0.015, 0.048)\n(0.023, 0.048)\n(-0.005, 0.045)\nDC(1)\n0.035\n0.035\n0.040\n0.030\n(0.023, 0.047)\n(0.015, 0.056)\n(0.030, 0.050)\n(-0.002, 0.062)\nOLS\n0.059\n0.095\n0.052\n0.091\n(0.056, 0.061)\n(0.093, 0.098)\n(0.05, 0.054)\n(0.089, 0.094)\n3M\n0.011\n-0.025\n0.003\n-0.013\n(0.004, 0.018)\n(-0.051, 0.002)\n(-0.004, 0.010)\n(-0.035, 0.009)\nDC(2)\n0.012\n0.014\n-0.033\n0.049\n(-0.019, 0.043) (-0.048, 0.084)\n(-0.075, 0.008)\n(-0.033, 0.123)\nDC(1)\n-0.024\n-0.003\n-0.049\n0.010\n(-0.059, 0.011)\n(-0.08, 0.074)\n(-0.081, -0.015) (-0.112, 0.136)\nFE\nNo\nYes\nNo\nYes\nTE\nNo\nNo\nYes\nYes\nNote: Top panel: estimates for the e\ufb00ect of Tobin\u2019s q on investment.\nBottom panel: estimates for the e\ufb00ect of cash \ufb02ow on investment. 95%\ncon\ufb01dence intervals in brackets. DC(B) indicates the divide-and-conquer\nestimator with B blocks per year.\n28\n\u2018\nTable 4\nSimulation: bias and standard deviation (n = 6, 000).\n\u03b20 = 0, \u03b10 = 0.05\n(1)\n(2)\n(3)\n(4)\nOLS\nb\u03b2\n0.000\n(0.000)\n0.000\n(0.000) 0.000 (0.000) 0.000 (0.000)\nb\u03b1\n0.050\n(0.001)\n0.050\n(0.001) 0.050 (0.001) 0.050 (0.001)\n3M\nb\u03b2\n0.084\n(8.099) -0.782 (110.119) 0.016 (1.342) 0.011 (2.157)\nb\u03b1 -0.106 (14.978)\n1.204 (162.353) 0.020 (2.538) 0.033 (3.251)\nDC(20)\nb\u03b2\n0.001\n(0.008)\n0.000\n(0.009) 0.001 (0.007) 0.001 (0.008)\nb\u03b1\n0.049\n(0.015)\n0.049\n(0.013) 0.049 (0.014) 0.049 (0.012)\nDC(40)\nb\u03b2\n0.001\n(0.005)\n0.001\n(0.005) 0.001 (0.005) 0.001 (0.005)\nb\u03b1\n0.048\n(0.010)\n0.049\n(0.009) 0.048 (0.010) 0.049 (0.008)\n\u03b20 = 0.025, \u03b10 = 0.05\n(1)\n(2)\n(3)\n(4)\nOLS\nb\u03b2\n0.011\n(0.000)\n0.009\n(0.000) 0.011 (0.000) 0.009 (0.000)\nb\u03b1\n0.077\n(0.001)\n0.075\n(0.001) 0.077 (0.001) 0.075 (0.001)\n3M\nb\u03b2\n0.025\n(0.000)\n0.025\n(0.000) 0.025 (0.000) 0.025 (0.000)\nb\u03b1\n0.050\n(0.001)\n0.050\n(0.001) 0.050 (0.001) 0.050 (0.001)\nDC(20)\nb\u03b2\n0.026\n(0.005)\n0.026\n(0.007) 0.026 (0.005) 0.026 (0.007)\nb\u03b1\n0.049\n(0.010)\n0.049\n(0.011) 0.049 (0.010) 0.049 (0.011)\nDC(40)\nb\u03b2\n0.025\n(0.005)\n0.024\n(0.007) 0.025 (0.005) 0.024 (0.007)\nb\u03b1\n0.049\n(0.010)\n0.052\n(0.010) 0.049 (0.009) 0.051 (0.010)\nFE\nNo\nYes\nNo\nYes\nTE\nNo\nNo\nYes\nYes\nNote: mean and standard deviation of the estimates for \u03b2 and \u03b1 when the\ncross-sectional dimension is n = 6, 000. For details, see the note following\nTable 1.\n29\nTable 5\nSimulation: coverage (n = 6, 000).\n\u03b20 = 0, \u03b10 = 0.05\n\u03b20 = 0.025, \u03b10 = 0.05\nOLS\n\u03b2\n95.1\n94.3\n95.0\n94.3\n0.0\n0.0\n0.0\n0.0\n\u03b1\n95.0\n94.5\n95.0\n94.5\n0.0\n0.0\n0.0\n0.0\n3M\n\u03b2\n97.0\n98.4\n97.0\n98.4\n95.0\n95.5\n95.0\n95.5\n\u03b1\n96.9\n98.4\n96.9\n98.3\n94.8\n94.5\n94.8\n94.5\nDC(20)\n\u03b2\n96.9\n96.9\n96.4\n96.8\n94.1\n94.0\n93.9\n94.3\n\u03b1\n96.8\n96.7\n96.5\n96.7\n93.9\n93.9\n93.9\n94.2\nDC(40)\n\u03b2\n96.0\n96.6\n96.0\n96.4\n94.1\n91.2\n94.5\n92.4\n\u03b1\n95.9\n96.3\n95.8\n96.2\n93.9\n91.0\n94.4\n92.2\nFE\nNo\nYes\nNo\nYes\nNo\nYes\nNo\nYes\nTE\nNo\nNo\nYes\nYes\nNo\nNo\nYes\nYes\nNote: coverage rate (\u00d7100) for the model and methods as described below\nTable 1 with cross-sectional dimension n = 6, 000. For details, see the note\nfollowing Table 2.\n30\nFigure 1: Application: estimates for the e\ufb00ect of Tobin\u2019s q on investment.\nFigure 2: Application: estimates for the e\ufb00ect of cash \ufb02ow on investment.\n31\nFigure 3: Application: estimates for the e\ufb00ect of Tobin\u2019s q on investment (1\nblock per year).\nFigure 4: Application: estimates for the e\ufb00ect of cash \ufb02ow on investment (1\nblock per year).\n32\n"}