{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "# import getpass\n",
    "import os\n",
    "from datetime import datetime\n",
    "from hashlib import md5\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import tiktoken\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "# from langchain_community.tools import WikipediaQueryRun\n",
    "# from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_text_splitters import TokenTextSplitter\n",
    "from pydantic import BaseModel, Field, conlist\n",
    "import openai\n",
    "from neo4j import GraphDatabase\n",
    "from langchain.callbacks.openai_info import OpenAICallbackHandler\n",
    "from langchain_core.rate_limiters import InMemoryRateLimiter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from graphdatascience import GraphDataScience\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"NEO4J_URI\"] = os.getenv('NEO4J_URI')\n",
    "os.environ[\"NEO4J_USERNAME\"] = os.getenv('NEO4J_USERNAME')\n",
    "os.environ[\"NEO4J_PASSWORD\"] = os.getenv('NEO4J_PASSWORD')\n",
    "os.environ[\"OPENAI_API_KEY\"] =  os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "graph = Neo4jGraph(refresh_schema=False)\n",
    "\n",
    "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:Chunk) REQUIRE c.id IS UNIQUE\")\n",
    "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:AtomicFact) REQUIRE c.id IS UNIQUE\")\n",
    "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (c:KeyElement) REQUIRE c.id IS UNIQUE\")\n",
    "graph.query(\"CREATE CONSTRAINT IF NOT EXISTS FOR (d:Document) REQUIRE d.id IS UNIQUE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the folder path\n",
    "folder_path = \"data/arxiv_stat_text\"\n",
    "documents_full = []\n",
    "document_names = []\n",
    "\n",
    "# Loop through the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    paper_path = os.path.join(folder_path, filename)\n",
    "    # Check if it's a file\n",
    "    if os.path.isfile(paper_path):\n",
    "        document_names.append(filename)\n",
    "        documents_full.append(open(paper_path).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "construction_system = \"\"\"\n",
    "You are an intelligent assistant tasked with extracting key elements and atomic facts from scientific articles to construct a knowledge graph. Your output must be structured to identify entities, relationships, and hierarchical connections. \n",
    "\n",
    "### JSON Output Requirements:\n",
    "- Ensure all output is valid JSON.\n",
    "- Each atomic fact must include:\n",
    "  1. `key_elements`: A **list of unique items** (authors, concepts, methods, etc.). **Limit: 1 to 10 items.** Avoid duplicate or malformed items.\n",
    "  2. `atomic_fact`: A **single, clear sentence** following the subject-predicate-object structure.\n",
    "- Ensure that `key_elements` contains no invalid characters (e.g., newlines, excessive commas, or special characters). Remove redundant or irrelevant entries.\n",
    "\n",
    "\n",
    "### KEY Extraction Guidelines:\n",
    "1. **Entities**: Extract and classify essential nouns and phrases into the following categories:\n",
    "   - **Authors**: Names of paper authors.\n",
    "   - **Concepts**: Theories, definitions, or models introduced or discussed.\n",
    "   - **Methods**: Experimental techniques, algorithms, or procedures.\n",
    "   - **Findings**: Results, discoveries, or key conclusions.\n",
    "   - **References**: Other papers, datasets, or sources cited. Full titles of other papers, datasets, or sources cited. Avoid vague references like \"reference [4]\" and replace them with the actual paper title or dataset name whenever possible. If the title is unavailable, include other identifying information (e.g., authors or publication year).\n",
    "   - **Theorems**: Mathematical or logical propositions.\n",
    "   - Cross-Document Entities: Highlight entities (authors, concepts, methods, etc.) that are shared with or similar to those in other documents.\n",
    "   \n",
    "2. **Relationships**: Identify and label verbs or phrases that connect the entities. Examples include:\n",
    "   - **\"Cites\"**: Links an author or paper to a referenced work.\n",
    "   - **\"Proposes\"**: Connects an author or paper to a method or concept.\n",
    "   - **\"Builds Upon\"**: Indicates that a concept/method is an extension of prior work.\n",
    "   - **\"Validates\"**: Links findings to methods or experiments.\n",
    "   - Cross-Document Relationships: Identify relationships that connect entities across multiple documents (e.g., the same concept being expanded upon by different papers).\n",
    "\n",
    "3. **Hierarchical Relationships**: Identify nested structures or dependencies, such as:\n",
    "   - A theorem being part of a model.\n",
    "   - A method comprising multiple steps or components.\n",
    "   - Cross-document hierarchies, such as a concept from one paper being part of a larger framework in another.\n",
    "\n",
    "4. **Atomic Facts**: Extract concise, indivisible facts with clear subject-predicate-object structure. Ensure each atomic fact aligns with the entities and relationships identified.\n",
    "\n",
    "5. **Key Elements**: Ensure that there are no redundant or repeated key elements. If the same key element appears more than once, only include it once\n",
    "\n",
    "6. **Relevance and Commonality**:\n",
    "   - Prioritize facts and relationships that are repeated across multiple papers.\n",
    "   - Highlight connections between entities that are pivotal or query-worthy.\n",
    "   - Emphasize shared or query-worthy entities and relationships between documents.\n",
    "\n",
    "7. **Connecting Documents**:\n",
    "When identifying entities, relationships, or references, always check for overlaps or connections with other documents (e.g., shared concepts, methods, authors, or references).\n",
    "Explicitly note when:\n",
    "    - An entity or relationship in the current document appears in or is similar to one from another document.\n",
    "    - A finding validates or contrasts a finding from another paper.\n",
    "    - A concept or method builds upon prior work from another document.\n",
    "\n",
    "8. **Additional Guidelines**:\n",
    "   - Replace pronouns with specific nouns (e.g., \"it\" becomes the actual method or concept).\n",
    "   - Include any implicit causal or temporal relationships.\n",
    "   - Present the key elements and atomic facts in the same language as the original text (e.g., English or Chinese).\n",
    "   - Limit each `key_elements` list to **10 items maximum**. If there are more than 10 entities, select the most relevant ones.\n",
    "   - Avoid including vague or redundant entries in `key_elements` such as `,`or `\\n` or `n` or `k`.\n",
    "   - Ensure that atomic facts are distinct and not repeated.\n",
    "\n",
    "Example Output:\n",
    "---\n",
    "**Key Elements**:\n",
    "- Authors: John Doe, Jane Smith\n",
    "- Concepts: Quantum Entanglement, Bell's Theorem\n",
    "- Methods: Double-slit experiment\n",
    "- Findings: Violation of Bell's inequality\n",
    "- References: Paper A (Einstein, 1935)\n",
    "- Cross-Document Entities: Bell's Theorem (also discussed in Paper B), Quantum Entanglement (validated by Paper C)\n",
    "\n",
    "**Atomic Facts**:\n",
    "1. John Doe and Jane Smith authored the paper.\n",
    "2. The paper proposes the concept of Quantum Entanglement.\n",
    "3. Bell's Theorem builds upon Einstein's 1935 work (Paper A).\n",
    "4. The Double-slit experiment validates Quantum Entanglement.\n",
    "5. The findings show a violation of Bell's inequality.\n",
    "6. Cross-Document Fact: Bell's Theorem is cited in Paper B and extended by Paper C.\n",
    "7. Cross-Document Fact: Quantum Entanglement was experimentally validated in Paper C, supporting findings in this paper.\n",
    "\n",
    "---\n",
    "Your output should maintain this structure and be as detailed and accurate as possible.\n",
    "\"\"\"\n",
    "\n",
    "construction_human = \"\"\"Use the given format to extract information from the \n",
    "following input: {input}\"\"\"\n",
    "\n",
    "construction_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            construction_system,\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            (\n",
    "                \"Use the given format to extract information from the \"\n",
    "                \"following input: {input}\"\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtomicFact(BaseModel):\n",
    "    key_elements: List[str]= Field(description=\"\"\"A list of essential entities (e.g., authors, theories, methods, findings) that are pivotal to the atomic fact.\n",
    "        These entities should align with the ones described in the prompt such as Authors, Concepts, Methods, Findings, References, Theorems, \n",
    "        and Cross-Document Entities. Ensure that the key elements are relevant and comprehensive. \"\"\") #Max length: 500 characters.\"\"\")\n",
    "    atomic_fact: str = Field(description=\"\"\"The smallest, indivisible facts, presented as concise sentences. These include\n",
    "        propositions, theories, existences, concepts, and implicit elements like logic, causality, event\n",
    "        sequences, interpersonal relationships, timelines, etc.\"\"\")\n",
    "\n",
    "class Extraction(BaseModel):\n",
    "    atomic_facts: List[AtomicFact] = Field(description=\"List of atomic facts\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0v/yyxwg9ld1z95p55ths3jt4bw0000gn/T/ipykernel_72413/472465510.py:1: LangChainBetaWarning: Introduced in 0.2.24. API subject to change.\n",
      "  rate_limiter = InMemoryRateLimiter(\n"
     ]
    }
   ],
   "source": [
    "rate_limiter = InMemoryRateLimiter(\n",
    "    requests_per_second=1,  # <-- Super slow! We can only make a request once every 10 seconds!!\n",
    "    check_every_n_seconds=0.1,  # Wake up every 100 ms to check whether allowed to make a request,\n",
    "    max_bucket_size=10,  # Controls the maximum burst size.\n",
    ")\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1, rate_limiter=rate_limiter)\n",
    "structured_llm = model.with_structured_output(Extraction)\n",
    "\n",
    "construction_chain = construction_prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_query = \"\"\"\n",
    "MERGE (d:Document {id:$document_name})\n",
    "WITH d\n",
    "UNWIND $data AS row\n",
    "MERGE (c:Chunk {id: row.chunk_id})\n",
    "SET c.text = row.chunk_text,\n",
    "    c.index = row.index,\n",
    "    c.document_name = row.document_name\n",
    "MERGE (d)-[:HAS_CHUNK]->(c)\n",
    "WITH c, row\n",
    "UNWIND row.atomic_facts AS af\n",
    "MERGE (a:AtomicFact {id: af.id})\n",
    "SET a.text = af.atomic_fact\n",
    "MERGE (c)-[:HAS_ATOMIC_FACT]->(a)\n",
    "WITH c, a, af\n",
    "UNWIND af.key_elements AS ke\n",
    "MERGE (k:KeyElement {id: ke})\n",
    "MERGE (a)-[:HAS_KEY_ELEMENT]->(k)\n",
    "\"\"\"\n",
    "\n",
    "def encode_md5(text):\n",
    "    return md5(text.encode(\"utf-8\")).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paper used 2k token size\n",
    "async def process_document(text, document_name, chunk_size=2000, chunk_overlap=200):\n",
    "    start = datetime.now()\n",
    "    print(f\"Started extraction at: {start}\")\n",
    "    text_splitter = TokenTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    texts = text_splitter.split_text(text)\n",
    "    print(f\"Total text chunks: {len(texts)}\")\n",
    "    tasks = [\n",
    "        asyncio.create_task(construction_chain.ainvoke({\"input\":chunk_text}))\n",
    "        for index, chunk_text in enumerate(texts)\n",
    "    ]\n",
    "    results = await asyncio.gather(*tasks)\n",
    "    print(f\"Finished LLM extraction after: {datetime.now() - start}\")\n",
    "    docs = [el.dict() for el in results]\n",
    "    for index, doc in enumerate(docs):\n",
    "        doc['chunk_id'] = encode_md5(texts[index])\n",
    "        doc['chunk_text'] = texts[index]\n",
    "        doc['index'] = index\n",
    "        for af in doc[\"atomic_facts\"]:\n",
    "            af[\"id\"] = encode_md5(af[\"atomic_fact\"])\n",
    "    # Import chunks/atomic facts/key elements\n",
    "    graph.query(import_query, \n",
    "            params={\"data\": docs, \"document_name\": document_name})\n",
    "    # Create next relationships between chunks\n",
    "    graph.query(\"\"\"MATCH (c:Chunk)<-[:HAS_CHUNK]-(d:Document)\n",
    "WHERE d.id = $document_name\n",
    "WITH c ORDER BY c.index WITH collect(c) AS nodes\n",
    "UNWIND range(0, size(nodes) -2) AS index\n",
    "WITH nodes[index] AS start, nodes[index + 1] AS end\n",
    "MERGE (start)-[:NEXT]->(end)\n",
    "\"\"\",\n",
    "           params={\"document_name\":document_name})\n",
    "    print(f\"Finished import at: {datetime.now() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_graph():\n",
    "#     query = \"\"\"\n",
    "#     MATCH (n)\n",
    "#     DETACH DELETE n\n",
    "#     \"\"\"\n",
    "#     graph.query(query)\n",
    "# clean_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "done = [\"1505.04215v1.pdf.json\", \n",
    "        \"2301.04439v1.pdf.json\", \n",
    "        \"2204.10909v2.pdf.json\",\n",
    "        \"2209.01679v3.pdf.json\", \n",
    "        \"1502.02355v2.pdf.json\", \n",
    "        \"1812.00492v1.pdf.json\", \n",
    "        \"1508.02925v1.pdf.json\",\n",
    "        \"1108.1098v1.pdf.json\"]\n",
    "trouble = [\"1605.04055v1.pdf.json\", \"1611.04701v2.pdf.json\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2201.01879v3.pdf.json\n",
      "Started extraction at: 2024-12-04 13:32:46.903427\n",
      "Total text chunks: 179\n"
     ]
    },
    {
     "ename": "CancelledError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m done \u001b[38;5;129;01mand\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m trouble:\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(name)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m process_document(text, name, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m, chunk_overlap\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mprocess_document\u001b[0;34m(text, document_name, chunk_size, chunk_overlap)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTotal text chunks: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m tasks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      9\u001b[0m     asyncio\u001b[38;5;241m.\u001b[39mcreate_task(construction_chain\u001b[38;5;241m.\u001b[39mainvoke({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m:chunk_text}))\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m index, chunk_text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(texts)\n\u001b[1;32m     11\u001b[0m ]\n\u001b[0;32m---> 12\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39mtasks)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinished LLM extraction after: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime\u001b[38;5;241m.\u001b[39mnow()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m docs \u001b[38;5;241m=\u001b[39m [el\u001b[38;5;241m.\u001b[39mdict() \u001b[38;5;28;01mfor\u001b[39;00m el \u001b[38;5;129;01min\u001b[39;00m results]\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/langchain_core/runnables/base.py:3066\u001b[0m, in \u001b[0;36mRunnableSequence.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m     part \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(step\u001b[38;5;241m.\u001b[39mainvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[1;32m   3065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m asyncio_accepts_context():\n\u001b[0;32m-> 3066\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(part(), context\u001b[38;5;241m=\u001b[39mcontext)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m   3067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3068\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mcreate_task(part())\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/langchain_core/runnables/base.py:5366\u001b[0m, in \u001b[0;36mRunnableBindingBase.ainvoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5360\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mainvoke\u001b[39m(\n\u001b[1;32m   5361\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5362\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5363\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5364\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5365\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5366\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39mainvoke(\n\u001b[1;32m   5367\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   5368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[1;32m   5369\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[1;32m   5370\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:307\u001b[0m, in \u001b[0;36mBaseChatModel.ainvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mainvoke\u001b[39m(\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    305\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    306\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m--> 307\u001b[0m     llm_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate_prompt(\n\u001b[1;32m    308\u001b[0m         [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[1;32m    309\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    310\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    311\u001b[0m         tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    312\u001b[0m         metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    313\u001b[0m         run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    314\u001b[0m         run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    316\u001b[0m     )\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ChatGeneration, llm_result\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:796\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21magenerate_prompt\u001b[39m(\n\u001b[1;32m    789\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    790\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    794\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    795\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magenerate(\n\u001b[1;32m    797\u001b[0m         prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    798\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:722\u001b[0m, in \u001b[0;36mBaseChatModel.agenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m AsyncCallbackManager\u001b[38;5;241m.\u001b[39mconfigure(\n\u001b[1;32m    703\u001b[0m     callbacks,\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata,\n\u001b[1;32m    710\u001b[0m )\n\u001b[1;32m    712\u001b[0m run_managers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mon_chat_model_start(\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_serialized,\n\u001b[1;32m    714\u001b[0m     messages,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    719\u001b[0m     run_id\u001b[38;5;241m=\u001b[39mrun_id,\n\u001b[1;32m    720\u001b[0m )\n\u001b[0;32m--> 722\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\n\u001b[1;32m    723\u001b[0m     \u001b[38;5;241m*\u001b[39m[\n\u001b[1;32m    724\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_agenerate_with_cache(\n\u001b[1;32m    725\u001b[0m             m,\n\u001b[1;32m    726\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m    727\u001b[0m             run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    728\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    729\u001b[0m         )\n\u001b[1;32m    730\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages)\n\u001b[1;32m    731\u001b[0m     ],\n\u001b[1;32m    732\u001b[0m     return_exceptions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    733\u001b[0m )\n\u001b[1;32m    734\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, res \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results):\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/langchain_core/language_models/chat_models.py:902\u001b[0m, in \u001b[0;36mBaseChatModel._agenerate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;66;03m# Apply the rate limiter after checking the cache, since\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;66;03m# we usually don't want to rate limit cache lookups, but\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# we do want to rate limit API requests.\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiter:\n\u001b[0;32m--> 902\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrate_limiter\u001b[38;5;241m.\u001b[39maacquire(blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    904\u001b[0m \u001b[38;5;66;03m# If stream is not explicitly set, check if implicitly requested by\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# astream_events() or astream_log(). Bail out if _astream not implemented\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_stream(\n\u001b[1;32m    907\u001b[0m     async_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    908\u001b[0m     run_manager\u001b[38;5;241m=\u001b[39mrun_manager,\n\u001b[1;32m    909\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    910\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/site-packages/langchain_core/rate_limiters.py:258\u001b[0m, in \u001b[0;36mInMemoryRateLimiter.aacquire\u001b[0;34m(self, blocking)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume()\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consume():\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# This code ignores the ASYNC110 warning which is a false positive in this\u001b[39;00m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;66;03m# case.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[38;5;66;03m# It needs to wake up to re-fill the tokens.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;66;03m# https://docs.astral.sh/ruff/rules/async-busy-wait/\u001b[39;00m\n\u001b[0;32m--> 258\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_every_n_seconds)  \u001b[38;5;66;03m# ruff: noqa: ASYNC110\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/deep/lib/python3.11/asyncio/tasks.py:649\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(delay, result)\u001b[0m\n\u001b[1;32m    645\u001b[0m h \u001b[38;5;241m=\u001b[39m loop\u001b[38;5;241m.\u001b[39mcall_later(delay,\n\u001b[1;32m    646\u001b[0m                     futures\u001b[38;5;241m.\u001b[39m_set_result_unless_cancelled,\n\u001b[1;32m    647\u001b[0m                     future, result)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m future\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    651\u001b[0m     h\u001b[38;5;241m.\u001b[39mcancel()\n",
      "\u001b[0;31mCancelledError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for text, name in zip(documents_full, document_names):\n",
    "    if name not in done and name not in trouble:\n",
    "        print(name)\n",
    "        await process_document(text, name, chunk_size=500, chunk_overlap=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = os.getenv('NEO4J_URI')\n",
    "user = os.getenv('NEO4J_USERNAME')\n",
    "password = os.getenv('NEO4J_PASSWORD')\n",
    "driver = GraphDatabase.driver(host, auth=(user, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.vectorstores.neo4j_vector import Neo4jVector\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "NEO4J_URI = os.getenv('NEO4J_URI')\n",
    "username = os.getenv('NEO4J_USERNAME')\n",
    "password = os.getenv('NEO4J_PASSWORD')\n",
    "\n",
    "vector_index = Neo4jVector.from_existing_graph(\n",
    "    OpenAIEmbeddings(),\n",
    "    url=NEO4J_URI,\n",
    "    username=username,\n",
    "    password=password,\n",
    "    node_label=\"Chunk\", #[\"Document\",\"Chunk\", \"AtomicFact\", \"KeyElement\"],\n",
    "    text_node_properties=[\"text\"],#[\"id\", \"text\", \"index\"], #['name', 'description', 'status'],\n",
    "    embedding_node_property=\"embedding\", #'embedding'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'what is the text in the first chunk of the first document?',\n",
       " 'result': \"I don't know.\",\n",
       " 'source_documents': [Document(metadata={}, page_content='\\ntext: '),\n",
       "  Document(metadata={}, page_content='\\ntext: '),\n",
       "  Document(metadata={}, page_content='\\ntext: '),\n",
       "  Document(metadata={}, page_content='\\ntext: ')]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_qa = RetrievalQA.from_chain_type(\n",
    "    llm=ChatOpenAI(model = \"gpt-4o-mini\"),\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_index.as_retriever(),\n",
    "    return_source_documents=True,\n",
    ")\n",
    "\n",
    "vector_qa({\"query\": \"what is the text in the first chunk of the first document?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=NEO4J_URI,\n",
    "    username=username,\n",
    "    password=password\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
